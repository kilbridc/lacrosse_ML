{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UEKbQ0W8PGGa",
        "MYQQjr3UUlEX",
        "6bjYIOFeWVmw",
        "_DIhKlMgXfED",
        "FuHHCFP8lJUI",
        "DpAF-_d_RWMy",
        "QLgMahseU-DZ",
        "Qm5H8QBsXOiI",
        "KvJcI_K2Y5TN",
        "aCgpR_YkaA2j",
        "Ds4BLJZc6b6p",
        "wkVY-cPy6qvi",
        "SfHrjrKv71RA",
        "3jlxpUOi8r4c",
        "1_kBLhRUGcw0",
        "SQUlQ-08IaEw",
        "DDXR_d6cJNpU",
        "XQhBhWtmN5cb",
        "sOZ3KcypD2B6",
        "6SpOpGD3Pbhz",
        "iPqpwZ7MPmBE",
        "7IWjUVfsSvGR",
        "v7ht5ZXYTMow",
        "xB6MpGXHc71p",
        "Zb6jJbBMUJuz"
      ],
      "mount_file_id": "1HsjV2NmnJ3zpk2z34Z9VdATaWCdv1UhR",
      "authorship_tag": "ABX9TyP6VoaLtukHLfxQ3vMb7Vfb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kilbridc/lacrosse_ML/blob/main/Final_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Scraping"
      ],
      "metadata": {
        "id": "UEKbQ0W8PGGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import requests\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "zwHbHIUmPLcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scraping the Game Scores"
      ],
      "metadata": {
        "id": "Gjs9I8MpPjRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will get the scores from 2017-2024 data. 2016 has bad data and 2025 is not a complete season yet."
      ],
      "metadata": {
        "id": "hDp5BRG8PTY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scores URL\n",
        "url = \"https://www.ncaa.com/scoreboard/lacrosse-men/d1/2025/04/23/all-conf\"\n",
        "page = requests.get(url)\n",
        "soup = BeautifulSoup(page.text, \"html\")\n",
        "\n",
        "#soup"
      ],
      "metadata": {
        "id": "Jk4URBsgPmb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will scrape this URL to get all of the scores from these seasons. For this, I simply manipulated the URL to get each date."
      ],
      "metadata": {
        "id": "ZMC2eU8dP4oD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all season scores\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "all_results = []\n",
        "\n",
        "# Loop through each season from 2016 to 2024, Feb 1st to May 30th\n",
        "for year in range(2017, 2025):\n",
        "    start_date = datetime(year, 2, 1)\n",
        "    end_date = datetime(year, 5, 30)\n",
        "    current_date = start_date\n",
        "\n",
        "    while current_date <= end_date:\n",
        "        # Format URL and date strings\n",
        "        url_date = current_date.strftime(\"%Y/%m/%d\")\n",
        "        formatted_date = current_date.strftime(\"%Y-%m-%d\")\n",
        "        url = f\"https://www.ncaa.com/scoreboard/lacrosse-men/d1/{url_date}\"\n",
        "\n",
        "        print(f\"Scraping {formatted_date}...\")\n",
        "\n",
        "        # Send request\n",
        "        headers = {\n",
        "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\n",
        "        }\n",
        "        try:\n",
        "            response = requests.get(url, headers=headers, timeout=15)\n",
        "            if response.status_code != 200:\n",
        "                print(f\"  Failed to load {formatted_date}\")\n",
        "                current_date += timedelta(days=1)\n",
        "                continue\n",
        "\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "            games = soup.find_all(\"div\", class_=\"gamePod\")\n",
        "\n",
        "            for game in games:\n",
        "                teams = game.find_all(\"li\")\n",
        "                if len(teams) != 2:\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    team_1 = teams[0].find(\"span\", class_=\"gamePod-game-team-name\").text.strip()\n",
        "                    score_1 = teams[0].find(\"span\", class_=\"gamePod-game-team-score\").text.strip()\n",
        "\n",
        "                    team_2 = teams[1].find(\"span\", class_=\"gamePod-game-team-name\").text.strip()\n",
        "                    score_2 = teams[1].find(\"span\", class_=\"gamePod-game-team-score\").text.strip()\n",
        "\n",
        "                    team_1_is_winner = \"winner\" in teams[0].get(\"class\", [])\n",
        "\n",
        "                    all_results.append({\n",
        "                        \"Date\": formatted_date,\n",
        "                        \"Year\": year,\n",
        "                        \"Team 1\": team_1,\n",
        "                        \"Score 1\": score_1,\n",
        "                        \"Team 2\": team_2,\n",
        "                        \"Score 2\": score_2,\n",
        "                        \"Winner\": team_1 if team_1_is_winner else team_2\n",
        "                    })\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error loading {formatted_date}: {e}\")\n",
        "\n",
        "        current_date += timedelta(days=1)\n",
        "\n",
        "# Create DataFrame\n",
        "df_all_seasons = pd.DataFrame(all_results)\n",
        "print(\"\\n✅ Scraping complete!\")\n",
        "df_all_seasons.head()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VyURtJBxPu6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will save this dataframe to a csv, so I don't have to re-scrape this."
      ],
      "metadata": {
        "id": "1pPBq4ZhQTzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make into csv\n",
        "df_all_seasons.to_csv(\"ncaa_lacrosse_all_seasons.csv\", index=False)\n",
        "# save to drive\n",
        "!cp ncaa_lacrosse_all_seasons.csv \"/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Raw Data\""
      ],
      "metadata": {
        "id": "OaMNqIsFQZjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scraping the statistics"
      ],
      "metadata": {
        "id": "DRIgTV_WQr1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This website was a little more difficult, so I used different headers to get in."
      ],
      "metadata": {
        "id": "AH8EDufXQr-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the function to scrape a single statistic from this website. It takes a stat_seq, which is how each statistic is reffered to in the URL."
      ],
      "metadata": {
        "id": "zXkRyJEBRH-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see this by looking at a URL.\n",
        "https://stats.ncaa.org/rankings/national_ranking?academic_year=2024.0&division=1.0&ranking_period=9.0&sport_code=MLA&stat_seq=561.0\n",
        "We can see the different arguments (separated by &), and by messing with these in browser, we can understand what they do."
      ],
      "metadata": {
        "id": "wEC8EolV2EYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example URL:\n",
        "# https://stats.ncaa.org/rankings/national_ranking?academic_year=2024.0&division=1.0&ranking_period=9.0&sport_code=MLA&stat_seq=561.0\n",
        "# need\n",
        "\n",
        "def scrape_ncaa_stat(start_year, end_year, stat_seq):\n",
        "    \"\"\"\n",
        "    Scrapes NCAA stats for a specific stat category (by stat_seq) over multiple academic years.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # these are for the URL\n",
        "    sport_code = \"MLA\"\n",
        "    division = \"1.0\"\n",
        "    base_url = \"https://stats.ncaa.org/rankings/national_ranking\"\n",
        "\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0\",\n",
        "        \"Referer\": \"https://www.stats.ncaa.org/\"\n",
        "    }\n",
        "\n",
        "    academic_years = [f\"{y}.0\" for y in range(start_year, end_year + 1)]\n",
        "\n",
        "    all_stats = []\n",
        "\n",
        "    for year in academic_years:\n",
        "        print(f\"\\n📅 Scraping Academic Year: {year}\")\n",
        "\n",
        "        # had to use ranking period of 24.0, then reverse back to the first entry, because every stat/year has one ranking with 24.0\n",
        "        params = {\n",
        "            \"academic_year\": year,\n",
        "            \"division\": division,\n",
        "            \"ranking_period\": \"24.0\",\n",
        "            \"sport_code\": sport_code,\n",
        "            \"stat_seq\": stat_seq\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.get(base_url, headers=headers, params=params, timeout=15)\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "            options = soup.select(\"select#rp option\")\n",
        "        except Exception as e:\n",
        "            print(f\"    ❌ Failed to load base page for year {year}: {e}\")\n",
        "            continue\n",
        "\n",
        "        if not options:\n",
        "            print(f\"    ⚠️ No ranking periods found for year {year}\")\n",
        "            continue\n",
        "\n",
        "        # this gets the list of all of the dates for that year\n",
        "        ranking_periods = [(opt[\"value\"], opt.text.strip()) for opt in options]\n",
        "        print(f\"    ↳ Found {len(ranking_periods)} ranking periods\")\n",
        "\n",
        "        # this goes through all of the dates\n",
        "        for rp_value, date in ranking_periods:\n",
        "            print(f\"    → Scraping {date} (rp={rp_value})\")\n",
        "\n",
        "            params[\"ranking_period\"] = rp_value\n",
        "            try:\n",
        "                rp_response = requests.get(base_url, headers=headers, params=params, timeout=15)\n",
        "                rp_soup = BeautifulSoup(rp_response.text, \"html.parser\")\n",
        "            except Exception as e:\n",
        "                print(f\"      ⚠️  Failed for {date}: {e}\")\n",
        "                continue\n",
        "\n",
        "            header_row = rp_soup.find(\"tr\", class_=\"splash_col_heading\")\n",
        "            if not header_row:\n",
        "                print(f\"      ⚠️ No header found for {date}\")\n",
        "                continue\n",
        "\n",
        "            column_names = [th.text.strip() for th in header_row.find_all(\"th\")]\n",
        "\n",
        "            data_rows = rp_soup.find_all(\"tr\")\n",
        "            for row in data_rows:\n",
        "                cols = row.find_all(\"td\")\n",
        "                if len(cols) == len(column_names):\n",
        "                    try:\n",
        "                        values = [col.text.strip() for col in cols]\n",
        "                        stat_dict = dict(zip(column_names, values))\n",
        "                        stat_dict[\"Date\"] = date\n",
        "                        stat_dict[\"Academic Year\"] = year\n",
        "                        all_stats.append(stat_dict)\n",
        "                    except Exception:\n",
        "                        continue\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(all_stats)\n",
        "\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "ggJd33EaRTtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code actually runs the previous function, but using all of the stat_categories. For each statistic, this code saves a new csv to my Raw Data Folder, and inside of the Statistics folder. This will take hours to run, so make sure your computer is charged"
      ],
      "metadata": {
        "id": "vAXYfzcRSHfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistics you want to scrape\n",
        "stat_categories = {\n",
        "    \"Assists per Game\": \"535.0\",\n",
        "    \"Caused Turnovers per Game\": \"561.0\",\n",
        "    \"Clearing %\": \"838.0\",\n",
        "    \"Faceoff %\": \"230.0\",\n",
        "    \"Groundballs per Game\": \"538.0\",\n",
        "    \"Man Down Defense\": \"232.0\",\n",
        "    \"Man Up Offense\": \"231.0\",\n",
        "    \"Opponent Clear %\": \"1213.0\",\n",
        "    \"Scoring Offense\": \"228.0\",\n",
        "    \"Saves per Game\": \"536.0\",\n",
        "    \"Scoring Defense\": \"229.0\",\n",
        "    \"Scoring Margin\": \"238.0\",\n",
        "    \"Shot %\": \"563.0\",\n",
        "    \"Turnovers per Game\": \"559.0\"\n",
        "}\n",
        "\n",
        "# for loop that loops through all of the statistics above and saves hem to there\n",
        "for stat_name, stat_seq in stat_categories.items():\n",
        "    print(f\"\\n🔍 Scraping: {stat_name} (stat_seq={stat_seq})\")\n",
        "\n",
        "    df = scrape_ncaa_stat(start_year=2015, end_year=2024, stat_seq=stat_seq)\n",
        "\n",
        "    # Create clean filename\n",
        "    safe_stat_name = stat_name.lower().replace(\" \", \"_\").replace(\"%\", \"percent\").replace(\"/\", \"_per_\")\n",
        "    filename = f\"ncaa_{safe_stat_name}_2017_2024.csv\"\n",
        "\n",
        "    # Save to Google Drive\n",
        "    save_path = f\"/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Raw Data/Statistics/{filename}\"\n",
        "    df.to_csv(save_path, index=False)\n",
        "\n",
        "    print(f\"✅ Saved to {save_path}\")\n"
      ],
      "metadata": {
        "id": "LJo6feG2SJ3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning and Merging"
      ],
      "metadata": {
        "id": "MYQQjr3UUlEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning Individual Sheets"
      ],
      "metadata": {
        "id": "6bjYIOFeWVmw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Right now, all of the data is stored in my drive, and it's all on different notebooks. The goal of this section is to combine all of the statistics into one cohesive .csv file."
      ],
      "metadata": {
        "id": "njmsDEFmUuDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "cAcg9YsWUq0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing we need to do is only keep the data columns we want."
      ],
      "metadata": {
        "id": "-dVYtBhJVpos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to clean a sheet\n",
        "# this will take the name of the sheet, and find the statistic associated with it, and remove the rest\n",
        "# for special ones (ones that don't match), we created rename_mapping to help us\n",
        "\n",
        "def clean_statistic(statistic_name, column_to_keep):\n",
        "    \"\"\"\n",
        "    Cleans a lacrosse statistic dataset with custom naming rules.\n",
        "\n",
        "    Args:\n",
        "        statistic_name (str): The original name of the statistic.\n",
        "        column_to_keep (str): The column to keep from the raw file.\n",
        "\n",
        "    Saves:\n",
        "        A cleaned CSV with corrected statistic naming.\n",
        "    \"\"\"\n",
        "\n",
        "    # Mapping for special renames\n",
        "    rename_mapping = {\n",
        "        \"Scoring Offense\": \"Goals per Game\",\n",
        "        \"Scoring Defense\": \"Goals Allowed per Game\",\n",
        "        \"Scoring Margin\": \"Average Margin\",\n",
        "        \"Man Down Defense\": \"Man Down Defense Percent\",\n",
        "        \"Man Up Offense\": \"Man Up Offense Percent\"\n",
        "    }\n",
        "\n",
        "    # Get the final name to use\n",
        "    final_stat_name = rename_mapping.get(statistic_name, statistic_name)\n",
        "\n",
        "    # Convert original statistic name to filename-friendly format\n",
        "    filename_stat = statistic_name.lower().replace(' ', '_')\n",
        "    file_path = f'/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Raw Data/Statistics/ncaa_{filename_stat}_2017_2024.csv'\n",
        "\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Keep only the necessary columns\n",
        "    df = df[['Date', 'Team', column_to_keep]]\n",
        "\n",
        "    # Rename the important column to the final name\n",
        "    df = df.rename(columns={column_to_keep: final_stat_name})\n",
        "\n",
        "    # Clean the Date column (first 10 characters only)\n",
        "    df['Date'] = df['Date'].str.slice(0, 10)\n",
        "\n",
        "    # Convert Date to datetime\n",
        "    df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y')\n",
        "\n",
        "    # Make sure the output folder exists\n",
        "    output_folder = '/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Clean Data'\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Save the cleaned file\n",
        "    cleaned_file_path = f'{output_folder}/clean_ncaa_{filename_stat}_2017_2024.csv'\n",
        "    df.to_csv(cleaned_file_path, index=False)\n",
        "\n",
        "    print(f\"Saved cleaned data for '{final_stat_name}' to {cleaned_file_path}\")\n"
      ],
      "metadata": {
        "id": "CvidKYf4VuOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistic to column mapping\n",
        "statistics = {\n",
        "    \"Assists per Game\": \"Per Game\",\n",
        "    \"Caused Turnovers per Game\": \"Per Game\",\n",
        "    \"Clearing Percent\": \"Pct.\",\n",
        "    \"Faceoff Percent\": \"Pct.\",\n",
        "    \"Groundballs per Game\": \"Per Game\",\n",
        "    \"Man Down Defense\": \"Pct.\",\n",
        "    \"Man Up Offense\": \"Pct.\",\n",
        "    \"Opponent Clear Percent\": \"Pct.\",\n",
        "    \"Scoring Offense\": \"Per Game\",\n",
        "    \"Saves per Game\": \"Per Game\",\n",
        "    \"Scoring Defense\": \"Per Game\",\n",
        "    \"Scoring Margin\": \"Margin\",\n",
        "    \"Shot Percent\": \"Pct.\",\n",
        "    \"Turnovers per Game\": \"Per Game\"\n",
        "}\n",
        "\n",
        "# Loop and apply cleaning\n",
        "for stat_name, column_name in statistics.items():\n",
        "    clean_statistic(stat_name, column_name)"
      ],
      "metadata": {
        "id": "p_4e8vd5WYHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merging the Data"
      ],
      "metadata": {
        "id": "_DIhKlMgXfED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing we need to do is remove all of the parathesis from the statistics' sheets' team names, that way they match the games sheet."
      ],
      "metadata": {
        "id": "OUgmsoTiXo8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Folder path with the existing cleaned stat files\n",
        "folder_path = '/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Clean Data'\n",
        "\n",
        "# Loop through all CSVs in the folder\n",
        "for file_name in os.listdir(folder_path):\n",
        "    if file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        # Load the file\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # If 'Team' column exists, clean it\n",
        "        if 'Team' in df.columns:\n",
        "            df['Team'] = df['Team'].str.split('(').str[0].str.strip()\n",
        "\n",
        "        # Save it back to the same file (overwrite)\n",
        "        df.to_csv(file_path, index=False)\n",
        "        print(f\"Cleaned and overwritten: {file_name}\")"
      ],
      "metadata": {
        "id": "BUfqH1DYXhbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you look at the games csv, there are a couple of errors. First, we need to normalize both team names and the winner. In addition, some of the names are very inconsistent. We fix both of these issues below.\n",
        "\n",
        "Beyond this, we need to combine the sheets together. Since the date on the game sheet is the date of the game, we want the closest associated statistic BEFORE the game."
      ],
      "metadata": {
        "id": "HD63yoFEiG97"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I_Sr296RjAen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load game data\n",
        "games_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Raw Data/ncaa_lacrosse_all_seasons.csv')\n",
        "games_df['Date'] = pd.to_datetime(games_df['Date'])\n",
        "\n",
        "# Normalize\n",
        "games_df['Team 1'] = games_df['Team 1'].str.strip().str.lower()\n",
        "games_df['Team 2'] = games_df['Team 2'].str.strip().str.lower()\n",
        "games_df['Winner'] = games_df['Winner'].str.strip().str.lower()\n",
        "\n",
        "# === Team name corrections ===\n",
        "name_corrections = {\n",
        "    \"albany\": \"ualbany\",\n",
        "    \"albany (ny)\": \"ualbany\",\n",
        "    \"army\": \"army west point\",\n",
        "    \"cleveland\": \"cleveland st.\",\n",
        "    \"detroit\": \"detroit mercy\",\n",
        "    \"loyola (md.)\": \"loyola maryland\",\n",
        "    \"mass.-lowell\": \"umass lowell\",\n",
        "    \"mt. st. mary's\": \"mount st. mary's\",\n",
        "    \"queens (nc)\": \"queens\",\n",
        "    \"st. john's (ny)\": \"st. john's\"\n",
        "}\n",
        "\n",
        "# Apply corrections\n",
        "games_df['Team 1'] = games_df['Team 1'].replace(name_corrections)\n",
        "games_df['Team 2'] = games_df['Team 2'].replace(name_corrections)"
      ],
      "metadata": {
        "id": "j4_al8z5jAcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function will take a games dataframe, and a stat dataframe, and combine them based on the team name."
      ],
      "metadata": {
        "id": "p8meOSsMYOWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_stat_to_games(games_df, stat_df, stat_column, output_column_base):\n",
        "    \"\"\"\n",
        "    Adds pre-game statistics for Team 1 and Team 2 to a game dataframe.\n",
        "\n",
        "    Args:\n",
        "        games_df: DataFrame containing game data with 'Date', 'Year', 'Team 1', 'Team 2'\n",
        "        stat_df: DataFrame with stats per team per date\n",
        "        stat_column: Name of the statistic column in stat_df (e.g., 'Assists per Game')\n",
        "        output_column_base: Base name for new columns (e.g., 'Assists per Game')\n",
        "\n",
        "    Returns:\n",
        "        games_df with two new columns added:\n",
        "        - f'Team 1 {output_column_base}'\n",
        "        - f'Team 2 {output_column_base}'\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure dates are datetime\n",
        "    games_df['Date'] = pd.to_datetime(games_df['Date'])\n",
        "    stat_df['Date'] = pd.to_datetime(stat_df['Date'])\n",
        "\n",
        "    # ensure everything is normalized\n",
        "    games_df['Team 1'] = games_df['Team 1'].str.strip().str.lower()\n",
        "    games_df['Team 2'] = games_df['Team 2'].str.strip().str.lower()\n",
        "    stat_df['Team'] = stat_df['Team'].str.strip().str.lower()\n",
        "\n",
        "    # Sort stats for efficient lookup\n",
        "    stat_df = stat_df.sort_values(by=['Team', 'Date'])\n",
        "\n",
        "    # Lookup function BEFORE the date of game\n",
        "    def get_stat(team, date, year):\n",
        "        records = stat_df[(stat_df['Team'] == team) &\n",
        "                          (stat_df['Date'] < date) &\n",
        "                          (stat_df['Date'].dt.year == year)]\n",
        "        if records.empty:\n",
        "            return ''\n",
        "        return records.iloc[-1][stat_column]\n",
        "\n",
        "    # Apply to Team 1\n",
        "    games_df[f'Team 1 {output_column_base}'] = games_df.apply(\n",
        "        lambda row: get_stat(row['Team 1'], row['Date'], row['Year']),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Apply to Team 2\n",
        "    games_df[f'Team 2 {output_column_base}'] = games_df.apply(\n",
        "        lambda row: get_stat(row['Team 2'], row['Date'], row['Year']),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    return games_df\n"
      ],
      "metadata": {
        "id": "LS07I95BYKrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Folder for stat files\n",
        "stat_folder = '/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Clean Data'\n",
        "\n",
        "# Stat columns and filenames\n",
        "statistics = {\n",
        "    \"Assists per Game\": \"assists_per_game\",\n",
        "    \"Caused Turnovers per Game\": \"caused_turnovers_per_game\",\n",
        "    \"Clearing Percent\": \"clearing_percent\",\n",
        "    \"Faceoff Percent\": \"faceoff_percent\",\n",
        "    \"Groundballs per Game\": \"groundballs_per_game\",\n",
        "    \"Man Down Defense Percent\": \"man_down_defense\",\n",
        "    \"Man Up Offense Percent\": \"man_up_offense\",\n",
        "    \"Opponent Clear Percent\": \"opponent_clear_percent\",\n",
        "    \"Goals per Game\": \"scoring_offense\",\n",
        "    \"Saves per Game\": \"saves_per_game\",\n",
        "    \"Goals Allowed per Game\": \"scoring_defense\",\n",
        "    \"Average Margin\": \"scoring_margin\",\n",
        "    \"Shot Percent\": \"shot_percent\",\n",
        "    \"Turnovers per Game\": \"turnovers_per_game\"\n",
        "}\n",
        "\n",
        "# Loop through each stat and add it to the game data\n",
        "for stat_column_name, file_key in statistics.items():\n",
        "    stat_file = f'{stat_folder}/clean_ncaa_{file_key}_2017_2024.csv'\n",
        "    if os.path.exists(stat_file):\n",
        "        print(f\"Processing {stat_column_name} from {file_key}...\")\n",
        "        stat_df = pd.read_csv(stat_file)\n",
        "        games_df = add_stat_to_games(games_df, stat_df, stat_column=stat_column_name, output_column_base=stat_column_name)\n",
        "    else:\n",
        "        print(f\"File not found: {stat_file}\")\n",
        "\n",
        "# Save final game data\n",
        "output_path = '/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Final Data/ncaa_lacrosse_with_all_stats.csv'\n",
        "games_df.to_csv(output_path, index=False)\n",
        "print(f\"Saved full dataset with stats to: {output_path}\")\n"
      ],
      "metadata": {
        "id": "W0k8zEC7Ydpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating RPI"
      ],
      "metadata": {
        "id": "FuHHCFP8lJUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last thing we need to do in this section is add RPI. RPI is a base metric to show how good a team is doing up until that point. It is calculated using 25% team record, 50% team's opponents' record, and 25% team's opponents' opponents' record. This will take some time to run, because it has to look back at the entire season for every game."
      ],
      "metadata": {
        "id": "dDBo3eY2lNYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_rpi(games_df):\n",
        "    games_df = games_df.copy()\n",
        "\n",
        "    # Build long-format dataframe of all matchups\n",
        "    team1_df = games_df[['Date', 'Year', 'Team 1', 'Team 2', 'Score 1', 'Score 2']].copy()\n",
        "    team1_df.columns = ['Date', 'Year', 'Team', 'Opponent', 'Team Score', 'Opponent Score']\n",
        "\n",
        "    team2_df = games_df[['Date', 'Year', 'Team 2', 'Team 1', 'Score 2', 'Score 1']].copy()\n",
        "    team2_df.columns = ['Date', 'Year', 'Team', 'Opponent', 'Team Score', 'Opponent Score']\n",
        "\n",
        "    all_games = pd.concat([team1_df, team2_df], ignore_index=True)\n",
        "    all_games['Win'] = (all_games['Team Score'] > all_games['Opponent Score']).astype(int)\n",
        "\n",
        "    # Helper to calculate RPI\n",
        "    def get_rpi_for_team(team, date, year):\n",
        "        team_games = all_games[(all_games['Team'] == team) &\n",
        "                               (all_games['Date'] < date) &\n",
        "                               (all_games['Year'] == year)]\n",
        "        if team_games.empty:\n",
        "            return None\n",
        "        wp = team_games['Win'].mean()\n",
        "\n",
        "        opponents = team_games['Opponent'].unique()\n",
        "        owp_list = []\n",
        "        for opp in opponents:\n",
        "            opp_games = all_games[(all_games['Team'] == opp) &\n",
        "                                  (all_games['Date'] < date) &\n",
        "                                  (all_games['Year'] == year) &\n",
        "                                  (all_games['Opponent'] != team)]\n",
        "            if not opp_games.empty:\n",
        "                owp_list.append(opp_games['Win'].mean())\n",
        "        owp = sum(owp_list) / len(owp_list) if owp_list else 0\n",
        "\n",
        "        oowp_list = []\n",
        "        for opp in opponents:\n",
        "            opp_games = all_games[(all_games['Team'] == opp) &\n",
        "                                  (all_games['Date'] < date) &\n",
        "                                  (all_games['Year'] == year)]\n",
        "            opp_opponents = opp_games['Opponent'].unique()\n",
        "            opp_owp_vals = []\n",
        "            for opp_opp in opp_opponents:\n",
        "                opp_opp_games = all_games[(all_games['Team'] == opp_opp) &\n",
        "                                          (all_games['Date'] < date) &\n",
        "                                          (all_games['Year'] == year) &\n",
        "                                          (all_games['Opponent'] != opp)]\n",
        "                if not opp_opp_games.empty:\n",
        "                    opp_owp_vals.append(opp_opp_games['Win'].mean())\n",
        "            if opp_owp_vals:\n",
        "                oowp_list.append(sum(opp_owp_vals) / len(opp_owp_vals))\n",
        "        oowp = sum(oowp_list) / len(oowp_list) if oowp_list else 0\n",
        "\n",
        "        return round(0.25 * wp + 0.50 * owp + 0.25 * oowp, 5)\n",
        "\n",
        "    # Add RPI columns with progress bar\n",
        "    tqdm.pandas(desc=\"Calculating Team 1 RPI\")\n",
        "    games_df['Team 1 RPI'] = games_df.progress_apply(\n",
        "        lambda row: get_rpi_for_team(row['Team 1'], row['Date'], row['Year']), axis=1)\n",
        "\n",
        "    tqdm.pandas(desc=\"Calculating Team 2 RPI\")\n",
        "    games_df['Team 2 RPI'] = games_df.progress_apply(\n",
        "        lambda row: get_rpi_for_team(row['Team 2'], row['Date'], row['Year']), axis=1)\n",
        "\n",
        "    return games_df\n",
        "\n",
        "\n",
        "games_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Final Data/ncaa_lacrosse_with_all_stats.csv')\n",
        "games_with_rpi = compute_rpi(games_df)\n",
        "#games_with_rpi.iloc[3500]\n",
        "\n",
        "# save to csv\n",
        "# Save the cleaned file\n",
        "cleaned_file_path = '/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Final Data/ncaa_lacrosse_with_all_stats.csv'\n",
        "games_with_rpi.to_csv(cleaned_file_path, index=False)"
      ],
      "metadata": {
        "id": "WaCHDwwWlb_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Logistic Regression"
      ],
      "metadata": {
        "id": "DpAF-_d_RWMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to begin to explore this data with a very basic logistic regression."
      ],
      "metadata": {
        "id": "SXSwk3d9RY93"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing the Data"
      ],
      "metadata": {
        "id": "QLgMahseU-DZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "qzMlkoh-SZOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in our dataset\n",
        "# Define the path to your CSV file\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Final Data/ncaa_lacrosse_with_RPI.csv\"\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "HWOMtzOCSM4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see we have 4160 games, but they are not all good. Let's fix our data. We don't want data where a team is not well represented, so we will elimate all of the games where either team has played less than 3 games."
      ],
      "metadata": {
        "id": "zxUvh4xGR_bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure Date is a datetime object\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Sort by date to ensure correct game order\n",
        "df = df.sort_values(by='Date').reset_index(drop=True)\n",
        "\n",
        "# Function to count games per team up to each date\n",
        "def add_game_counts(df):\n",
        "    team_game_counts = {}\n",
        "\n",
        "    game_counts = []\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        year = row['Year']\n",
        "        team1 = row['Team 1']\n",
        "        team2 = row['Team 2']\n",
        "        date = row['Date']\n",
        "\n",
        "        # Create keys based on year and team\n",
        "        key1 = (year, team1)\n",
        "        key2 = (year, team2)\n",
        "\n",
        "        # Get current game count\n",
        "        count1 = team_game_counts.get(key1, 0)\n",
        "        count2 = team_game_counts.get(key2, 0)\n",
        "\n",
        "        game_counts.append((count1, count2))\n",
        "\n",
        "        # Increment game counts AFTER the game\n",
        "        team_game_counts[key1] = count1 + 1\n",
        "        team_game_counts[key2] = count2 + 1\n",
        "\n",
        "    df['Team 1 Games Played'] = [c[0] for c in game_counts]\n",
        "    df['Team 2 Games Played'] = [c[1] for c in game_counts]\n",
        "\n",
        "    return df\n",
        "\n",
        "# Add game counts\n",
        "df = add_game_counts(df)\n",
        "\n",
        "# Filter: keep only games where both teams have played at least 2 games before this one\n",
        "df = df[(df['Team 1 Games Played'] >= 2) & (df['Team 2 Games Played'] >= 2)]\n",
        "\n",
        "# Preview cleaned data\n",
        "#df.head()\n",
        "\n",
        "print(df.shape)\n"
      ],
      "metadata": {
        "id": "7t12iDJMS2QJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some of the games also have a 0-0 score, so let's remove them."
      ],
      "metadata": {
        "id": "8hXhe8ulTUUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove games with a 0-0 score (invalid data)\n",
        "df = df[~((df['Score 1'] == 0) & (df['Score 2'] == 0))]\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "T1gv-0GbTXgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Opponent Clear Percentage wasn't tracked before the 2020 season, so we have to keep that in mind. First let's remove all of the sames where there is a NaN statistic, and we will worry about the opponent clear percentage later."
      ],
      "metadata": {
        "id": "SihgaLRVTh6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of Opponent Clear Percent columns to exclude from NaN filtering\n",
        "excluded_columns = ['Team 1 Opponent Clear Percent', 'Team 2 Opponent Clear Percent']\n",
        "\n",
        "# Columns to check for NaNs (all except excluded ones)\n",
        "columns_to_check = [col for col in df.columns if col not in excluded_columns]\n",
        "\n",
        "# Drop rows with NaNs in any of those columns\n",
        "df = df.dropna(subset=columns_to_check).reset_index(drop=True)\n",
        "\n",
        "# Preview cleaned data\n",
        "#df.head()\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "2J0cj_OkTgSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are going to split the dataset into pre2020 and post2020. This is for a couple of reasons. First, there were two massive rule changes (one in 2019 and one in 2020). Splitting the data here allows us to see the effect of these rule changes on lacrosse. In addition, opponent clear percentage was not tracked before 2019, so this also allows us to more easily look at our weights."
      ],
      "metadata": {
        "id": "kE5jOrFdT3kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset by year so I can do the same thing to opponent clear percentage AFTER 2020\n",
        "df_pre2020 = df[(df['Year'] >= 2015) & (df['Year'] <= 2019)].copy()\n",
        "df_post2020 = df[(df['Year'] >= 2020) & (df['Year'] <= 2024)].copy()\n",
        "\n",
        "\n",
        "# Check sizes\n",
        "print(\"Pre-2020 dataset shape:\", df_pre2020.shape)\n",
        "print(\"2020+ dataset shape:\", df_post2020.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "7SGHfj_xUFCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop NaN in opponent clear percentage for post 2020\n",
        "df_post2020 = df_post2020.dropna(subset=['Team 1 Opponent Clear Percent', 'Team 2 Opponent Clear Percent']).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "oPn4AuYjUJRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pre-2020 dataset shape:\", df_pre2020.shape)\n",
        "print(\"2020+ dataset shape:\", df_post2020.shape)"
      ],
      "metadata": {
        "id": "71eqL6p2UNqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset has 39 features. First, we are simply going to use differential features to see what is important to a team's success. For this, we will just subtract the team 2 stats from the team 1 stats."
      ],
      "metadata": {
        "id": "Q6Hah8X0UZeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify matching statistic pairs\n",
        "team1_prefix = \"Team 1 \"\n",
        "team2_prefix = \"Team 2 \"\n",
        "\n",
        "# Collect column pairs for which both Team 1 and Team 2 have values\n",
        "stat_columns = []\n",
        "for col in df_pre2020.columns:\n",
        "    if col.startswith(team1_prefix):\n",
        "        team1_stat = col\n",
        "        team2_stat = team2_prefix + col[len(team1_prefix):]\n",
        "        if team2_stat in df_pre2020.columns:\n",
        "            stat_columns.append((team1_stat, team2_stat))\n",
        "\n",
        "# Function to compute differential features\n",
        "def add_differential_features(df, stat_columns):\n",
        "    for t1_col, t2_col in stat_columns:\n",
        "        diff_col = \"Diff \" + t1_col[len(team1_prefix):]\n",
        "        df[diff_col] = df[t1_col] - df[t2_col]\n",
        "    return df\n",
        "\n",
        "# Apply to both datasets\n",
        "df_pre2020 = add_differential_features(df_pre2020, stat_columns)\n",
        "df_post2020 = add_differential_features(df_post2020, stat_columns)\n",
        "\n",
        "# Preview updated data\n",
        "df_pre2020[[col for col in df_pre2020.columns if col.startswith(\"Diff\")]].head()\n"
      ],
      "metadata": {
        "id": "ujqoOL_nUnFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to normalize these differential features."
      ],
      "metadata": {
        "id": "Wtk36ifxUwZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_differential_features_only(df):\n",
        "    # Identify differential columns\n",
        "    diff_cols = [col for col in df.columns if col.startswith(\"Diff \") and df[col].notna().all()]\n",
        "\n",
        "    # Standardize only those columns\n",
        "    scaler = StandardScaler()\n",
        "    df[diff_cols] = scaler.fit_transform(df[diff_cols])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply normalization to both datasets\n",
        "df_pre2020 = normalize_differential_features_only(df_pre2020)\n",
        "df_post2020 = normalize_differential_features_only(df_post2020)"
      ],
      "metadata": {
        "id": "JEbTnzQHUv2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will do this same pre-processing multiple times throughout this notebook."
      ],
      "metadata": {
        "id": "ZFdenZm333vw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Logistic Regression"
      ],
      "metadata": {
        "id": "_aSW0dJ2VDJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, learning_curve\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, make_scorer\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "qht3k4oCUR44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre 2020 first"
      ],
      "metadata": {
        "id": "ynfSNMsNVI2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define target variable\n",
        "df_pre2020['Win'] = (df_pre2020['Winner'] == df_pre2020['Team 1']).astype(int)\n",
        "#df_pre2020.head()"
      ],
      "metadata": {
        "id": "pNeOzdu3VPiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Select only differential features\n",
        "# Define differential feature columns\n",
        "all_diff_features = [col for col in df_pre2020.columns if col.startswith(\"Diff \") and df_pre2020[col].notna().all()]\n",
        "# Remove games played or any unwanted features\n",
        "diff_features = [col for col in all_diff_features if 'Games Played' not in col]\n",
        "\n",
        "\n",
        "# Create X and y\n",
        "X = df_pre2020[diff_features].copy()\n",
        "y = df_pre2020['Win']"
      ],
      "metadata": {
        "id": "5LTa9_P4VX4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "GGiwItoHVbJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Train logistic regression\n",
        "model_pre2020 = LogisticRegression()\n",
        "model_pre2020.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "VLQJZ1XUVbbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Evaluate model\n",
        "y_pred = model_pre2020.predict(X_test)\n",
        "accuracy_pre2020 = accuracy_score(y_test, y_pred)\n",
        "f1_pre2020 = f1_score(y_test, y_pred)\n",
        "report_pre2020 = classification_report(y_test, y_pred)"
      ],
      "metadata": {
        "id": "_vOXdSRDVbd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Feature importance\n",
        "coefficients_pre2020 = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_pre2020.coef_[0]\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_pre2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_pre2020:.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_pre2020)\n",
        "print(\"\\nTop 10 Most Influential Features:\")\n",
        "print(coefficients_pre2020.head(10))  # Top 10 features\n",
        "print(\"\\n10 Least Influential Features:\")\n",
        "print(coefficients_pre2020.tail(10))\n",
        "\n",
        "# 8. Learning Curve\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(max_iter=1000),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plotting\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression - Pre 2020)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AYkap3CNVbgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now for post 2020"
      ],
      "metadata": {
        "id": "kTp3GVMiVbiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define target variable\n",
        "df_post2020['Win'] = (df_post2020['Winner'] == df_post2020['Team 1']).astype(int)\n",
        "\n",
        "# 2. Select only differential features\n",
        "all_diff_features = [col for col in df_post2020.columns if col.startswith(\"Diff \") and df_post2020[col].notna().all()]\n",
        "diff_features = [col for col in all_diff_features if 'Games Played' not in col]\n",
        "\n",
        "# 3. Create X and y\n",
        "X = df_post2020[diff_features].copy()\n",
        "y = df_post2020['Win']\n",
        "\n",
        "# 4. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Train logistic regression\n",
        "model_post2020 = LogisticRegression(max_iter=1000)\n",
        "model_post2020.fit(X_train, y_train)\n",
        "\n",
        "# 6. Evaluate model\n",
        "y_pred = model_post2020.predict(X_test)\n",
        "accuracy_post2020 = accuracy_score(y_test, y_pred)\n",
        "f1_post2020 = f1_score(y_test, y_pred)\n",
        "report_post2020 = classification_report(y_test, y_pred)\n",
        "\n",
        "# 7. Feature importance\n",
        "coefficients_post2020 = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_post2020.coef_[0]\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_post2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_post2020:.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_post2020)\n",
        "print(\"\\nTop 10 Most Influential Features:\")\n",
        "print(coefficients_post2020.head(10))  # Top 10 features\n",
        "print(\"\\n10 Least Influential Features:\")\n",
        "print(coefficients_post2020.tail(10))\n",
        "\n",
        "# 8. Learning Curve\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(max_iter=1000),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plotting\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression - Post 2020)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "q6erUQLqVzz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both of these actually got us solid results. By looking at the learning curves, we can see that both of these did a pretty good job of neither overfitting or underfitting. The pre 2020 data has some overfitting, and we can try and reduce the complexity to fix this. We can also see which statistics have the highest impact on a team's success."
      ],
      "metadata": {
        "id": "N-kFYH4V44E6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regularization"
      ],
      "metadata": {
        "id": "Qm5H8QBsXOiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this next section, we add regularization to see if it improves performance, and to give us more insight on which statistics are important (and not important) to a team's success."
      ],
      "metadata": {
        "id": "uQ1cp5C76ulL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ridge Regularization (L2)"
      ],
      "metadata": {
        "id": "KvJcI_K2Y5TN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge Regularization will reduce ALL of the weights of the features."
      ],
      "metadata": {
        "id": "ijnD8RtS6y67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "qXO95HJRXSbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pre 2020\n",
        "\n",
        "# Select only differential features\n",
        "all_diff_features = [col for col in df_pre2020.columns if col.startswith(\"Diff \") and df_pre2020[col].notna().all()]\n",
        "diff_features = [col for col in all_diff_features if 'Games Played' not in col]\n",
        "\n",
        "# Create X and y\n",
        "X = df_pre2020[diff_features].copy()\n",
        "y = df_pre2020['Win']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train logistic regression with L2 regularization -- ridge\n",
        "model_pre2020 = LogisticRegression(penalty='l2', solver='liblinear', C=0.1)\n",
        "model_pre2020.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model_pre2020.predict(X_test)\n",
        "accuracy_pre2020 = accuracy_score(y_test, y_pred)\n",
        "f1_pre2020 = f1_score(y_test, y_pred)\n",
        "report_pre2020 = classification_report(y_test, y_pred)\n",
        "\n",
        "# Feature importance\n",
        "coefficients_pre2020 = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_pre2020.coef_[0]\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "# Output\n",
        "print(f\"Accuracy: {accuracy_pre2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_pre2020:.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_pre2020)\n",
        "print(\"\\nTop 10 Most Influential Features:\")\n",
        "print(coefficients_pre2020.head(10))\n",
        "print(\"\\n10 Least Influential Features:\")\n",
        "print(coefficients_pre2020.tail(10))\n",
        "\n",
        "# 8. Learning Curve\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(max_iter=1000),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plotting\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression - Pre 2020) with Ridge Regularization')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OeIzm3QZXZKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# post 2020\n",
        "\n",
        "# Define target variable\n",
        "df_post2020['Win'] = (df_post2020['Winner'] == df_post2020['Team 1']).astype(int)\n",
        "\n",
        "# Select only differential features\n",
        "all_diff_features = [col for col in df_post2020.columns if col.startswith(\"Diff \") and df_post2020[col].notna().all()]\n",
        "diff_features = [col for col in all_diff_features if 'Games Played' not in col]\n",
        "\n",
        "# Create X and y\n",
        "X = df_post2020[diff_features].copy()\n",
        "y = df_post2020['Win']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train logistic regression with L2 regularization\n",
        "model_post2020 = LogisticRegression(penalty='l2', solver='liblinear', C=0.01)\n",
        "model_post2020.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model_post2020.predict(X_test)\n",
        "accuracy_post2020 = accuracy_score(y_test, y_pred)\n",
        "f1_post2020 = f1_score(y_test, y_pred)\n",
        "report_post2020 = classification_report(y_test, y_pred)\n",
        "\n",
        "# Feature importance\n",
        "coefficients_post2020 = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_post2020.coef_[0]\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "# Output\n",
        "print(f\"Accuracy: {accuracy_post2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_post2020:.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_post2020)\n",
        "print(\"\\nTop 10 Most Influential Features:\")\n",
        "print(coefficients_post2020.head(10))\n",
        "print(\"\\n10 Least Influential Features:\")\n",
        "print(coefficients_post2020.tail(10))\n",
        "\n",
        "\n",
        "# 8. Learning Curve\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(max_iter=1000),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plotting\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression - Post 2020) with Ridge Regularization')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mk3l-6xpXo_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lasso Regularization (L1)"
      ],
      "metadata": {
        "id": "pll7m0ODY-JU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pre 2020\n",
        "\n",
        "# Select only differential features\n",
        "all_diff_features = [col for col in df_pre2020.columns if col.startswith(\"Diff \") and df_pre2020[col].notna().all()]\n",
        "diff_features = [col for col in all_diff_features if 'Games Played' not in col]\n",
        "\n",
        "# Create X and y\n",
        "X = df_pre2020[diff_features].copy()\n",
        "y = df_pre2020['Win']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train logistic regression with L2 regularization -- ridge\n",
        "model_pre2020 = LogisticRegression(penalty='l1', solver='liblinear', C=0.1)\n",
        "model_pre2020.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model_pre2020.predict(X_test)\n",
        "accuracy_pre2020 = accuracy_score(y_test, y_pred)\n",
        "f1_pre2020 = f1_score(y_test, y_pred)\n",
        "report_pre2020 = classification_report(y_test, y_pred)\n",
        "\n",
        "# Feature importance\n",
        "coefficients_pre2020 = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_pre2020.coef_[0]\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "# Output\n",
        "print(f\"Accuracy: {accuracy_pre2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_pre2020:.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_pre2020)\n",
        "print(\"\\nTop 10 Most Influential Features:\")\n",
        "print(coefficients_pre2020.head(10))\n",
        "print(\"\\n10 Least Influential Features:\")\n",
        "print(coefficients_pre2020.tail(10))\n",
        "\n",
        "# 8. Learning Curve\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(max_iter=1000),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plotting\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression - Pre 2020) with Lasso Regularization')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PafjNvBJZCp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# post 2020\n",
        "\n",
        "# Define target variable\n",
        "df_post2020['Win'] = (df_post2020['Winner'] == df_post2020['Team 1']).astype(int)\n",
        "\n",
        "# Select only differential features\n",
        "all_diff_features = [col for col in df_post2020.columns if col.startswith(\"Diff \") and df_post2020[col].notna().all()]\n",
        "diff_features = [col for col in all_diff_features if 'Games Played' not in col]\n",
        "\n",
        "# Create X and y\n",
        "X = df_post2020[diff_features].copy()\n",
        "y = df_post2020['Win']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train logistic regression with L2 regularization\n",
        "model_post2020 = LogisticRegression(penalty='l1', solver='liblinear', C=0.01)\n",
        "model_post2020.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model_post2020.predict(X_test)\n",
        "accuracy_post2020 = accuracy_score(y_test, y_pred)\n",
        "f1_post2020 = f1_score(y_test, y_pred)\n",
        "report_post2020 = classification_report(y_test, y_pred)\n",
        "\n",
        "# Feature importance\n",
        "coefficients_post2020 = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_post2020.coef_[0]\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "# Output\n",
        "print(f\"Accuracy: {accuracy_post2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_post2020:.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_post2020)\n",
        "print(\"\\nTop 10 Most Influential Features:\")\n",
        "print(coefficients_post2020.head(10))\n",
        "print(\"\\n10 Least Influential Features:\")\n",
        "print(coefficients_post2020.tail(10))\n",
        "\n",
        "# 8. Learning Curve\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(max_iter=1000),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plotting\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression - Post 2020) with Lasso Regularization')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gRR9S0dbZCr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both regularizations helped the post 2020 data the most, and did not have much of an effect on the pre 2020 data."
      ],
      "metadata": {
        "id": "yoDkzOyF9XNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "aCgpR_YkaA2j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm curious to see how a random forest will perform on the same exact data set."
      ],
      "metadata": {
        "id": "_wDNA1FX-Li3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing the Data"
      ],
      "metadata": {
        "id": "LmO0Rf4UaJZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "J9X6F_-LaT_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in our dataset\n",
        "# Define the path to your CSV file\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Final Data/ncaa_lacrosse_with_RPI.csv\"\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "O0j4QdWeaT_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure Date is a datetime object\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Sort by date to ensure correct game order\n",
        "df = df.sort_values(by='Date').reset_index(drop=True)\n",
        "\n",
        "# Function to count games per team up to each date\n",
        "def add_game_counts(df):\n",
        "    team_game_counts = {}\n",
        "\n",
        "    game_counts = []\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        year = row['Year']\n",
        "        team1 = row['Team 1']\n",
        "        team2 = row['Team 2']\n",
        "        date = row['Date']\n",
        "\n",
        "        # Create keys based on year and team\n",
        "        key1 = (year, team1)\n",
        "        key2 = (year, team2)\n",
        "\n",
        "        # Get current game count\n",
        "        count1 = team_game_counts.get(key1, 0)\n",
        "        count2 = team_game_counts.get(key2, 0)\n",
        "\n",
        "        game_counts.append((count1, count2))\n",
        "\n",
        "        # Increment game counts AFTER the game\n",
        "        team_game_counts[key1] = count1 + 1\n",
        "        team_game_counts[key2] = count2 + 1\n",
        "\n",
        "    df['Team 1 Games Played'] = [c[0] for c in game_counts]\n",
        "    df['Team 2 Games Played'] = [c[1] for c in game_counts]\n",
        "\n",
        "    return df\n",
        "\n",
        "# Add game counts\n",
        "df = add_game_counts(df)\n",
        "\n",
        "# Filter: keep only games where both teams have played at least 2 games before this one\n",
        "df = df[(df['Team 1 Games Played'] >= 2) & (df['Team 2 Games Played'] >= 2)]\n",
        "\n",
        "# Preview cleaned data\n",
        "#df.head()\n",
        "\n",
        "print(df.shape)\n"
      ],
      "metadata": {
        "id": "5YDcBxpOaT_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove games with a 0-0 score (invalid data)\n",
        "df = df[~((df['Score 1'] == 0) & (df['Score 2'] == 0))]\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "QBgO3SPLaT_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of Opponent Clear Percent columns to exclude from NaN filtering\n",
        "excluded_columns = ['Team 1 Opponent Clear Percent', 'Team 2 Opponent Clear Percent']\n",
        "\n",
        "# Columns to check for NaNs (all except excluded ones)\n",
        "columns_to_check = [col for col in df.columns if col not in excluded_columns]\n",
        "\n",
        "# Drop rows with NaNs in any of those columns\n",
        "df = df.dropna(subset=columns_to_check).reset_index(drop=True)\n",
        "\n",
        "# Preview cleaned data\n",
        "#df.head()\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "uBUPPoLmaT_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset by year so I can do the same thing to opponent clear percentage AFTER 2020\n",
        "df_pre2020 = df[(df['Year'] >= 2015) & (df['Year'] <= 2019)].copy()\n",
        "df_post2020 = df[(df['Year'] >= 2020) & (df['Year'] <= 2024)].copy()\n",
        "\n",
        "\n",
        "# Check sizes\n",
        "print(\"Pre-2020 dataset shape:\", df_pre2020.shape)\n",
        "print(\"2020+ dataset shape:\", df_post2020.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "zwegMrt2aT_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop NaN in opponent clear percentage for post 2020\n",
        "df_post2020 = df_post2020.dropna(subset=['Team 1 Opponent Clear Percent', 'Team 2 Opponent Clear Percent']).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "xcvlZbRYaT_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pre-2020 dataset shape:\", df_pre2020.shape)\n",
        "print(\"2020+ dataset shape:\", df_post2020.shape)"
      ],
      "metadata": {
        "id": "wG4K5nKPaT_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify matching statistic pairs\n",
        "team1_prefix = \"Team 1 \"\n",
        "team2_prefix = \"Team 2 \"\n",
        "\n",
        "# Collect column pairs for which both Team 1 and Team 2 have values\n",
        "stat_columns = []\n",
        "for col in df_pre2020.columns:\n",
        "    if col.startswith(team1_prefix):\n",
        "        team1_stat = col\n",
        "        team2_stat = team2_prefix + col[len(team1_prefix):]\n",
        "        if team2_stat in df_pre2020.columns:\n",
        "            stat_columns.append((team1_stat, team2_stat))\n",
        "\n",
        "# Function to compute differential features\n",
        "def add_differential_features(df, stat_columns):\n",
        "    for t1_col, t2_col in stat_columns:\n",
        "        diff_col = \"Diff \" + t1_col[len(team1_prefix):]\n",
        "        df[diff_col] = df[t1_col] - df[t2_col]\n",
        "    return df\n",
        "\n",
        "# Apply to both datasets\n",
        "df_pre2020 = add_differential_features(df_pre2020, stat_columns)\n",
        "df_post2020 = add_differential_features(df_post2020, stat_columns)\n",
        "\n",
        "# Preview updated data\n",
        "df_pre2020[[col for col in df_pre2020.columns if col.startswith(\"Diff\")]].head()\n"
      ],
      "metadata": {
        "id": "t2qmqF1IaT_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_differential_features_only(df):\n",
        "    # Identify differential columns\n",
        "    diff_cols = [col for col in df.columns if col.startswith(\"Diff \") and df[col].notna().all()]\n",
        "\n",
        "    # Standardize only those columns\n",
        "    scaler = StandardScaler()\n",
        "    df[diff_cols] = scaler.fit_transform(df[diff_cols])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply normalization to both datasets\n",
        "df_pre2020 = normalize_differential_features_only(df_pre2020)\n",
        "df_post2020 = normalize_differential_features_only(df_post2020)"
      ],
      "metadata": {
        "id": "4cXT5hheaT_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Random Forest"
      ],
      "metadata": {
        "id": "C9PvIj-QaoUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "def run_rf_with_report(df, label, drop_columns=None):\n",
        "    # 1. Create binary target\n",
        "    df['Team 1 Win'] = (df['Winner'].str.lower() == df['Team 1'].str.lower()).astype(int)\n",
        "\n",
        "    # 2. Drop unwanted columns\n",
        "    if drop_columns:\n",
        "        df = df.drop(columns=drop_columns, errors='ignore')\n",
        "\n",
        "    # 3. Use only relevant differential features\n",
        "    diff_features = [col for col in df.columns if col.startswith('Diff') and 'Games Played' not in col]\n",
        "\n",
        "    # 4. Drop rows with missing values\n",
        "    df_clean = df.dropna(subset=diff_features)\n",
        "    X = df_clean[diff_features]\n",
        "    y = df_clean['Team 1 Win']\n",
        "\n",
        "    # 5. Train/test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 6. Train Random Forest\n",
        "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "\n",
        "    # 7. Evaluate\n",
        "    y_pred = rf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    # 8. Feature importances\n",
        "    importances = rf.feature_importances_\n",
        "    feature_importance_df = pd.DataFrame({\n",
        "        'Feature': diff_features,\n",
        "        'Importance': importances\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    # 9. Output report\n",
        "    print(f\"{label} Accuracy: {accuracy:.3f}\")\n",
        "    print(f\"{label} F1 Score: {f1:.3f}\\n\")\n",
        "    print(\"Classification Report:\\n\", report)\n",
        "\n",
        "    print(\"Top 10 Most Influential Features:\")\n",
        "    print(feature_importance_df.head(10).to_string(index=False))\n",
        "\n",
        "    print(\"\\n10 Least Influential Features:\")\n",
        "    print(feature_importance_df.tail(10).to_string(index=False))\n"
      ],
      "metadata": {
        "id": "pTzVg7jTanqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_rf_with_report(df_pre2020, \"Pre-2020\", drop_columns=['Diff Opponent Clear Percent'])"
      ],
      "metadata": {
        "id": "NVwD6b6G_TQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_rf_with_report(df_post2020, \"Post-2020\")"
      ],
      "metadata": {
        "id": "K-MraDYd_W3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "Ds4BLJZc6b6p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do a XGBoost to see if it does better."
      ],
      "metadata": {
        "id": "I2Vu-tNY6hug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing the Data"
      ],
      "metadata": {
        "id": "wkVY-cPy6qvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "MYZutRhJ6xJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in our dataset\n",
        "# Define the path to your CSV file\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Final Data/ncaa_lacrosse_with_RPI.csv\"\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "O30igrDv6xJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure Date is a datetime object\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Sort by date to ensure correct game order\n",
        "df = df.sort_values(by='Date').reset_index(drop=True)\n",
        "\n",
        "# Function to count games per team up to each date\n",
        "def add_game_counts(df):\n",
        "    team_game_counts = {}\n",
        "\n",
        "    game_counts = []\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        year = row['Year']\n",
        "        team1 = row['Team 1']\n",
        "        team2 = row['Team 2']\n",
        "        date = row['Date']\n",
        "\n",
        "        # Create keys based on year and team\n",
        "        key1 = (year, team1)\n",
        "        key2 = (year, team2)\n",
        "\n",
        "        # Get current game count\n",
        "        count1 = team_game_counts.get(key1, 0)\n",
        "        count2 = team_game_counts.get(key2, 0)\n",
        "\n",
        "        game_counts.append((count1, count2))\n",
        "\n",
        "        # Increment game counts AFTER the game\n",
        "        team_game_counts[key1] = count1 + 1\n",
        "        team_game_counts[key2] = count2 + 1\n",
        "\n",
        "    df['Team 1 Games Played'] = [c[0] for c in game_counts]\n",
        "    df['Team 2 Games Played'] = [c[1] for c in game_counts]\n",
        "\n",
        "    return df\n",
        "\n",
        "# Add game counts\n",
        "df = add_game_counts(df)\n",
        "\n",
        "# Filter: keep only games where both teams have played at least 2 games before this one\n",
        "df = df[(df['Team 1 Games Played'] >= 2) & (df['Team 2 Games Played'] >= 2)]\n",
        "\n",
        "# Preview cleaned data\n",
        "#df.head()\n",
        "\n",
        "print(df.shape)\n"
      ],
      "metadata": {
        "id": "fTNp8fNs6xJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove games with a 0-0 score (invalid data)\n",
        "df = df[~((df['Score 1'] == 0) & (df['Score 2'] == 0))]\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "eXvvRfdG6xJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of Opponent Clear Percent columns to exclude from NaN filtering\n",
        "excluded_columns = ['Team 1 Opponent Clear Percent', 'Team 2 Opponent Clear Percent']\n",
        "\n",
        "# Columns to check for NaNs (all except excluded ones)\n",
        "columns_to_check = [col for col in df.columns if col not in excluded_columns]\n",
        "\n",
        "# Drop rows with NaNs in any of those columns\n",
        "df = df.dropna(subset=columns_to_check).reset_index(drop=True)\n",
        "\n",
        "# Preview cleaned data\n",
        "#df.head()\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "o7t6mZiK6xJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset by year so I can do the same thing to opponent clear percentage AFTER 2020\n",
        "df_pre2020 = df[(df['Year'] >= 2015) & (df['Year'] <= 2019)].copy()\n",
        "df_post2020 = df[(df['Year'] >= 2020) & (df['Year'] <= 2024)].copy()\n",
        "\n",
        "\n",
        "# Check sizes\n",
        "print(\"Pre-2020 dataset shape:\", df_pre2020.shape)\n",
        "print(\"2020+ dataset shape:\", df_post2020.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "vyGDVFjL6xJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop NaN in opponent clear percentage for post 2020\n",
        "df_post2020 = df_post2020.dropna(subset=['Team 1 Opponent Clear Percent', 'Team 2 Opponent Clear Percent']).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "f_mP64Z06xJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pre-2020 dataset shape:\", df_pre2020.shape)\n",
        "print(\"2020+ dataset shape:\", df_post2020.shape)"
      ],
      "metadata": {
        "id": "wL3vf3pJ6xJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify matching statistic pairs\n",
        "team1_prefix = \"Team 1 \"\n",
        "team2_prefix = \"Team 2 \"\n",
        "\n",
        "# Collect column pairs for which both Team 1 and Team 2 have values\n",
        "stat_columns = []\n",
        "for col in df_pre2020.columns:\n",
        "    if col.startswith(team1_prefix):\n",
        "        team1_stat = col\n",
        "        team2_stat = team2_prefix + col[len(team1_prefix):]\n",
        "        if team2_stat in df_pre2020.columns:\n",
        "            stat_columns.append((team1_stat, team2_stat))\n",
        "\n",
        "# Function to compute differential features\n",
        "def add_differential_features(df, stat_columns):\n",
        "    for t1_col, t2_col in stat_columns:\n",
        "        diff_col = \"Diff \" + t1_col[len(team1_prefix):]\n",
        "        df[diff_col] = df[t1_col] - df[t2_col]\n",
        "    return df\n",
        "\n",
        "# Apply to both datasets\n",
        "df_pre2020 = add_differential_features(df_pre2020, stat_columns)\n",
        "df_post2020 = add_differential_features(df_post2020, stat_columns)\n",
        "\n",
        "# Preview updated data\n",
        "df_pre2020[[col for col in df_pre2020.columns if col.startswith(\"Diff\")]].head()\n"
      ],
      "metadata": {
        "id": "G4B6zkN_6xJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_differential_features_only(df):\n",
        "    # Identify differential columns\n",
        "    diff_cols = [col for col in df.columns if col.startswith(\"Diff \") and df[col].notna().all()]\n",
        "\n",
        "    # Standardize only those columns\n",
        "    scaler = StandardScaler()\n",
        "    df[diff_cols] = scaler.fit_transform(df[diff_cols])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply normalization to both datasets\n",
        "df_pre2020 = normalize_differential_features_only(df_pre2020)\n",
        "df_post2020 = normalize_differential_features_only(df_post2020)"
      ],
      "metadata": {
        "id": "NhRrvh_l6xJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the XGBoost Model."
      ],
      "metadata": {
        "id": "y9WH5YlG6_Ve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This training is similar to the previous ones, except there are different metrics for trees, all of which I print in a table. This is important to understand what each of these do."
      ],
      "metadata": {
        "id": "30z6oe75KCD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Imports ---\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "U-cTohkj7JIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_xgb_with_report(df, label, drop_columns=None):\n",
        "    # 1. Create binary target\n",
        "    df['Team 1 Win'] = (df['Winner'].str.lower() == df['Team 1'].str.lower()).astype(int)\n",
        "\n",
        "    # 2. Drop unwanted columns\n",
        "    if drop_columns:\n",
        "        df = df.drop(columns=drop_columns, errors='ignore')\n",
        "\n",
        "    # 3. Select features\n",
        "    diff_features = [col for col in df.columns if col.startswith('Diff') and 'Games Played' not in col]\n",
        "\n",
        "    # 4. Drop rows with missing values\n",
        "    df_clean = df.dropna(subset=diff_features)\n",
        "    X = df_clean[diff_features]\n",
        "    y = df_clean['Team 1 Win']\n",
        "\n",
        "    # 5. Train/test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 6. Train XGBoost model\n",
        "    model = xgb.XGBClassifier(n_estimators=100, eval_metric='logloss', random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # 7. Evaluate\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    # 8. Feature importance\n",
        "    importance_dict = model.get_booster().get_score(importance_type='gain')\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': list(importance_dict.keys()),\n",
        "        'Importance': list(importance_dict.values())\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    # Fill in any missing features (e.g., zero importance)\n",
        "    all_features_df = pd.DataFrame({'Feature': diff_features})\n",
        "    importance_df = all_features_df.merge(importance_df, on='Feature', how='left').fillna(0)\n",
        "\n",
        "    # 9. Output\n",
        "\n",
        "    print(f\"{label} Accuracy (XGBoost): {accuracy:.3f}\")\n",
        "    print(f\"{label} F1 Score: {f1:.3f}\\n\")\n",
        "    print(\"Classification Report:\\n\", report)\n",
        "\n",
        "    '''\n",
        "    print(\"Top 10 Most Influential Features:\")\n",
        "    print(importance_df.head(10).to_string(index=False))\n",
        "\n",
        "    print(\"\\n10 Least Influential Features:\")\n",
        "    print(importance_df.tail(10).to_string(index=False))\n",
        "    '''\n",
        "\n",
        "    # 10. Compare multiple importance types\n",
        "    importance_types = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n",
        "    importance_dicts = {}\n",
        "\n",
        "    # Collect importance for each type\n",
        "    for imp_type in importance_types:\n",
        "        importance_dicts[imp_type] = model.get_booster().get_score(importance_type=imp_type)\n",
        "\n",
        "    # Build DataFrame\n",
        "    importance_df = pd.DataFrame({'Feature': diff_features})\n",
        "\n",
        "    for imp_type in importance_types:\n",
        "        imp_data = pd.Series(importance_dicts[imp_type])\n",
        "        importance_df[imp_type] = importance_df['Feature'].map(imp_data).fillna(0)\n",
        "\n",
        "    # Sort by gain (or any other metric you prefer)\n",
        "    importance_df = importance_df.sort_values(by='gain', ascending=False)\n",
        "\n",
        "    # Print the table\n",
        "    print(\"\\nFull Feature Importance Comparison:\")\n",
        "    print(importance_df.head(15).to_string(index=False))"
      ],
      "metadata": {
        "id": "hZSkCfHL7Ddw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_xgb_with_report(df_pre2020, \"Pre-2020\", drop_columns=['Diff Opponent Clear Percent'])"
      ],
      "metadata": {
        "id": "FYRrBYxlIjjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_xgb_with_report(df_post2020, \"Post-2020\")"
      ],
      "metadata": {
        "id": "0iT6oozTIjl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering: Opposing Statistics"
      ],
      "metadata": {
        "id": "SfHrjrKv71RA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the linear logistic regression performed pretty well and gave us valuable insight, I think there are more things to explore. In the first trainings of these models, we just compared how one team's statistics paired up to the other team's statsitcs, one by one. But in a real lacrosse game, offense doesn't play against offense. I want to see how these interact with each other. For example, I want to see the difference between Team 1's Offense and Team 2's Defense, and want to see if these have a bigger impact."
      ],
      "metadata": {
        "id": "63F2LWvH73bh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing the Data"
      ],
      "metadata": {
        "id": "3jlxpUOi8r4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to preprocess this data a little differently to get more of these statistics."
      ],
      "metadata": {
        "id": "zYY5eguo8wEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "jKAU-uPl8__O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in our dataset\n",
        "# Define the path to your CSV file\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Final Data/ncaa_lacrosse_with_RPI.csv\"\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "uJJ1JTNm8__O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure Date is a datetime object\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Sort by date to ensure correct game order\n",
        "df = df.sort_values(by='Date').reset_index(drop=True)\n",
        "\n",
        "# Function to count games per team up to each date\n",
        "def add_game_counts(df):\n",
        "    team_game_counts = {}\n",
        "\n",
        "    game_counts = []\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        year = row['Year']\n",
        "        team1 = row['Team 1']\n",
        "        team2 = row['Team 2']\n",
        "        date = row['Date']\n",
        "\n",
        "        # Create keys based on year and team\n",
        "        key1 = (year, team1)\n",
        "        key2 = (year, team2)\n",
        "\n",
        "        # Get current game count\n",
        "        count1 = team_game_counts.get(key1, 0)\n",
        "        count2 = team_game_counts.get(key2, 0)\n",
        "\n",
        "        game_counts.append((count1, count2))\n",
        "\n",
        "        # Increment game counts AFTER the game\n",
        "        team_game_counts[key1] = count1 + 1\n",
        "        team_game_counts[key2] = count2 + 1\n",
        "\n",
        "    df['Team 1 Games Played'] = [c[0] for c in game_counts]\n",
        "    df['Team 2 Games Played'] = [c[1] for c in game_counts]\n",
        "\n",
        "    return df\n",
        "\n",
        "# Add game counts\n",
        "df = add_game_counts(df)\n",
        "\n",
        "# Filter: keep only games where both teams have played at least 2 games before this one\n",
        "df = df[(df['Team 1 Games Played'] >= 2) & (df['Team 2 Games Played'] >= 2)]\n",
        "\n",
        "# Preview cleaned data\n",
        "#df.head()\n",
        "\n",
        "print(df.shape)\n"
      ],
      "metadata": {
        "id": "hWq6l3GB8__O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove games with a 0-0 score (invalid data)\n",
        "df = df[~((df['Score 1'] == 0) & (df['Score 2'] == 0))]\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "90AroKXL8__O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of Opponent Clear Percent columns to exclude from NaN filtering\n",
        "excluded_columns = ['Team 1 Opponent Clear Percent', 'Team 2 Opponent Clear Percent']\n",
        "\n",
        "# Columns to check for NaNs (all except excluded ones)\n",
        "columns_to_check = [col for col in df.columns if col not in excluded_columns]\n",
        "\n",
        "# Drop rows with NaNs in any of those columns\n",
        "df = df.dropna(subset=columns_to_check).reset_index(drop=True)\n",
        "\n",
        "# Preview cleaned data\n",
        "#df.head()\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "IgGPMGeM8__P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing we need to do is change the saves per game to a save percentage. This allows us to compare shot percentage to opposing team's save percentage. We can calculate this with saves per game/saves per game + goals allowed."
      ],
      "metadata": {
        "id": "0x1R_nUV-jqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add a goalie save pct (saves per game / [saves per game + goals allowed per game])\n",
        "\n",
        "# Calculate goalie save percentage for Team 1\n",
        "df['Team 1 Save Percent'] = df['Team 1 Saves per Game'] / (\n",
        "    df['Team 1 Saves per Game'] + df['Team 1 Goals Allowed per Game']\n",
        ")\n",
        "\n",
        "# Calculate goalie save percentage for Team 2\n",
        "df['Team 2 Save Percent'] = df['Team 2 Saves per Game'] / (\n",
        "    df['Team 2 Saves per Game'] + df['Team 2 Goals Allowed per Game']\n",
        ")"
      ],
      "metadata": {
        "id": "KU_nbwa3-jqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset by year so I can do the same thing to opponent clear percentage AFTER 2020\n",
        "df_pre2020 = df[(df['Year'] >= 2015) & (df['Year'] <= 2019)].copy()\n",
        "df_post2020 = df[(df['Year'] >= 2020) & (df['Year'] <= 2024)].copy()\n",
        "\n",
        "\n",
        "# Check sizes\n",
        "print(\"Pre-2020 dataset shape:\", df_pre2020.shape)\n",
        "print(\"2020+ dataset shape:\", df_post2020.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "IfH0Jkmt8__P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop NaN in opponent clear percentage for post 2020\n",
        "df_post2020 = df_post2020.dropna(subset=['Team 1 Opponent Clear Percent', 'Team 2 Opponent Clear Percent']).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "-lzzOgIr8__P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pre-2020 dataset shape:\", df_pre2020.shape)\n",
        "print(\"2020+ dataset shape:\", df_post2020.shape)"
      ],
      "metadata": {
        "id": "y8Olash98__P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's add our differential features just in case\n",
        "# Identify matching statistic pairs\n",
        "team1_prefix = \"Team 1 \"\n",
        "team2_prefix = \"Team 2 \"\n",
        "\n",
        "# Collect column pairs for which both Team 1 and Team 2 have values\n",
        "stat_columns = []\n",
        "for col in df_pre2020.columns:\n",
        "    if col.startswith(team1_prefix):\n",
        "        team1_stat = col\n",
        "        team2_stat = team2_prefix + col[len(team1_prefix):]\n",
        "        if team2_stat in df_pre2020.columns:\n",
        "            stat_columns.append((team1_stat, team2_stat))\n",
        "\n",
        "# Function to compute differential features\n",
        "def add_differential_features(df, stat_columns):\n",
        "    for t1_col, t2_col in stat_columns:\n",
        "        diff_col = \"Diff \" + t1_col[len(team1_prefix):]\n",
        "        df[diff_col] = df[t1_col] - df[t2_col]\n",
        "    return df\n",
        "\n",
        "# Apply to both datasets\n",
        "df_pre2020 = add_differential_features(df_pre2020, stat_columns)\n",
        "df_post2020 = add_differential_features(df_post2020, stat_columns)\n",
        "\n",
        "# Preview updated data\n",
        "df_pre2020[[col for col in df_pre2020.columns if col.startswith(\"Diff\")]].head()"
      ],
      "metadata": {
        "id": "nzuUiY1nENPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to add in our new columns. In the first run, I am just going to train with these new columns."
      ],
      "metadata": {
        "id": "qTzkylQ59l0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# see the columns we currently have\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "cHSXfS9D9rAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the new columns I will add:\n",
        "\n",
        "Team 1 Goals Per Game vs Team 2 Goals Allowed Per Game\n",
        "\n",
        "Team 1 Turnovers per Game vs Team 2 Caused Turnovers per Game\n",
        "\n",
        "Team 1 Clearing Percent vs Team 2 Opponent Clearing Percent\n",
        "\n",
        "Team 1 Man Up Offense Percent vs Team 2 Man Down Defense Percent\n",
        "\n",
        "Team 1 Goalie Percent vs Team 2 Shot Percent\n",
        "\n",
        "These are the columns that already stack up against each other:\n",
        "\n",
        "Team 1 Faceoff Percent vs Team 2 Faceoff Percent\n",
        "\n",
        "Team 1 RPI vs Team 2 RPI\n",
        "\n",
        "Team 1 Average Margin vs Team 2 Average Margin"
      ],
      "metadata": {
        "id": "15OGqXaY9xHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for df in [df_pre2020, df_post2020]:\n",
        "    # Goals per Game vs Goals Allowed\n",
        "    df['T1_Offense_vs_T2_Defense'] = df['Team 1 Goals per Game'] - df['Team 2 Goals Allowed per Game']\n",
        "    df['T2_Offense_vs_T1_Defense'] = df['Team 2 Goals per Game'] - df['Team 1 Goals Allowed per Game']\n",
        "\n",
        "    # Turnovers vs Caused Turnovers\n",
        "    df['T1_Turnovers_vs_T2_CausedTOs'] = df['Team 1 Turnovers per Game'] - df['Team 2 Caused Turnovers per Game']\n",
        "    df['T2_Turnovers_vs_T1_CausedTOs'] = df['Team 2 Turnovers per Game'] - df['Team 1 Caused Turnovers per Game']\n",
        "\n",
        "    # Clearing Percent vs Opponent Clearing Percent\n",
        "    df['T1_Clear_vs_T2_OppClear'] = df['Team 1 Clearing Percent'] - df['Team 2 Opponent Clear Percent']\n",
        "    df['T2_Clear_vs_T1_OppClear'] = df['Team 2 Clearing Percent'] - df['Team 1 Opponent Clear Percent']\n",
        "\n",
        "    # Man-Up Offense vs Man-Down Defense\n",
        "    df['T1_ManUp_vs_T2_ManDown'] = df['Team 1 Man Up Offense Percent'] - df['Team 2 Man Down Defense Percent']\n",
        "    df['T2_ManUp_vs_T1_ManDown'] = df['Team 2 Man Up Offense Percent'] - df['Team 1 Man Down Defense Percent']\n",
        "\n",
        "    # Save Percent vs Shot Percent\n",
        "    df['T1_Goalie_vs_T2_Shooting'] = df['Team 1 Save Percent'] - df['Team 2 Shot Percent']\n",
        "    df['T2_Goalie_vs_T1_Shooting'] = df['Team 2 Save Percent'] - df['Team 1 Shot Percent']\n",
        "\n",
        "    # Faceoff Percent difference\n",
        "    df['Faceoff_Percent_Diff'] = df['Team 1 Faceoff Percent'] - df['Team 2 Faceoff Percent']\n",
        "\n",
        "    # RPI difference\n",
        "    df['RPI_Diff'] = df['Team 1 RPI'] - df['Team 2 RPI']\n",
        "\n",
        "    # Margin difference\n",
        "    df['Margin_Diff'] = df['Team 1 Average Margin'] - df['Team 2 Average Margin']\n",
        "\n",
        "# view new data\n",
        "# print(df_pre2020.iloc[0])\n",
        "print(df_post2020.iloc[0])"
      ],
      "metadata": {
        "id": "WZ3LxoiU9uHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize our new features\n",
        "def normalize_differential_features_only(df):\n",
        "    # Identify differential columns\n",
        "\n",
        "    # List of features to normalize\n",
        "    diff_cols = [\n",
        "        'T1_Offense_vs_T2_Defense', 'T2_Offense_vs_T1_Defense',\n",
        "        'T1_Turnovers_vs_T2_CausedTOs', 'T2_Turnovers_vs_T1_CausedTOs',\n",
        "        'T1_Clear_vs_T2_OppClear', 'T2_Clear_vs_T1_OppClear',\n",
        "        'T1_ManUp_vs_T2_ManDown', 'T2_ManUp_vs_T1_ManDown',\n",
        "        'T1_Goalie_vs_T2_Shooting', 'T2_Goalie_vs_T1_Shooting',\n",
        "        'Faceoff_Percent_Diff', 'RPI_Diff', 'Margin_Diff'\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Standardize only those columns\n",
        "    scaler = StandardScaler()\n",
        "    df[diff_cols] = scaler.fit_transform(df[diff_cols])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply normalization to both datasets\n",
        "df_pre2020 = normalize_differential_features_only(df_pre2020)\n",
        "df_post2020 = normalize_differential_features_only(df_post2020)\n",
        "\n",
        "# Note: The warnings are from pre 2020 opponent clear percentage"
      ],
      "metadata": {
        "id": "ndEBkS3E_bVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression on New Data"
      ],
      "metadata": {
        "id": "1_kBLhRUGcw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are not going to do any regularization."
      ],
      "metadata": {
        "id": "tWHwT9TqG7HL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "OoAbPLrO_CX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre 2020\n",
        "# 1. Define target variable\n",
        "df_pre2020['Win'] = (df_pre2020['Winner'] == df_pre2020['Team 1']).astype(int)\n",
        "#df_post2020.head()\n",
        "\n",
        "# 2. Select only differential features\n",
        "diff_features = [\n",
        "    'T1_Offense_vs_T2_Defense', 'T2_Offense_vs_T1_Defense',\n",
        "    'T1_Turnovers_vs_T2_CausedTOs', 'T2_Turnovers_vs_T1_CausedTOs',\n",
        "    'T1_ManUp_vs_T2_ManDown', 'T2_ManUp_vs_T1_ManDown',\n",
        "    'T1_Goalie_vs_T2_Shooting', 'T2_Goalie_vs_T1_Shooting',\n",
        "    'Faceoff_Percent_Diff', 'RPI_Diff', 'Margin_Diff'\n",
        "]\n",
        "\n",
        "# Create X and y\n",
        "X = df_pre2020[diff_features].copy()\n",
        "y = df_pre2020['Win']\n",
        "\n",
        "# 3. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Train logistic regression\n",
        "# Don't use regularization\n",
        "model_pre2020 = LogisticRegression(solver='liblinear')\n",
        "model_pre2020.fit(X_train, y_train)\n",
        "\n",
        "# 5. Evaluate model\n",
        "y_pred = model_pre2020.predict(X_test)\n",
        "accuracy_pre2020 = accuracy_score(y_test, y_pred)\n",
        "f1_pre2020 = f1_score(y_test, y_pred)\n",
        "report_pre2020 = classification_report(y_test, y_pred)\n",
        "\n",
        "# 6. Feature importance\n",
        "coefficients_pre2020 = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_pre2020.coef_[0]\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_pre2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_pre2020:.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_pre2020)\n",
        "print(coefficients_pre2020.head(10))  # Top 10 features\n",
        "print(\"\\n10 Least Influential Features:\")\n",
        "print(coefficients_pre2020.tail(10))\n",
        "\n",
        "# 8. Learning Curve\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(max_iter=1000),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plotting\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression with New Features - Pre 2020)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PQsgGdAdMkyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Post 2020\n",
        "# 1. Define target variable\n",
        "df_post2020['Win'] = (df_post2020['Winner'] == df_post2020['Team 1']).astype(int)\n",
        "#df_post2020.head()\n",
        "\n",
        "# 2. Select only differential features\n",
        "diff_features = [\n",
        "    'T1_Offense_vs_T2_Defense', 'T2_Offense_vs_T1_Defense',\n",
        "    'T1_Turnovers_vs_T2_CausedTOs', 'T2_Turnovers_vs_T1_CausedTOs',\n",
        "    'T1_Clear_vs_T2_OppClear', 'T2_Clear_vs_T1_OppClear',\n",
        "    'T1_ManUp_vs_T2_ManDown', 'T2_ManUp_vs_T1_ManDown',\n",
        "    'T1_Goalie_vs_T2_Shooting', 'T2_Goalie_vs_T1_Shooting',\n",
        "    'Faceoff_Percent_Diff', 'RPI_Diff', 'Margin_Diff'\n",
        "]\n",
        "\n",
        "# Create X and y\n",
        "X = df_post2020[diff_features].copy()\n",
        "y = df_post2020['Win']\n",
        "\n",
        "# 3. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Train logistic regression\n",
        "# Don't use regularization\n",
        "model_post2020 = LogisticRegression(solver='liblinear')\n",
        "model_post2020.fit(X_train, y_train)\n",
        "\n",
        "# 5. Evaluate model\n",
        "y_pred = model_post2020.predict(X_test)\n",
        "accuracy_post2020 = accuracy_score(y_test, y_pred)\n",
        "f1_post2020 = f1_score(y_test, y_pred)\n",
        "report_post2020 = classification_report(y_test, y_pred)\n",
        "\n",
        "# 6. Feature importance\n",
        "coefficients_post2020 = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_post2020.coef_[0]\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_post2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_post2020:.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_post2020)\n",
        "print(coefficients_post2020.head(10))  # Top 10 features\n",
        "print(\"\\n10 Least Influential Features:\")\n",
        "print(coefficients_post2020.tail(10))\n",
        "\n",
        "# 8. Learning Curve\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(max_iter=1000),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plotting\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression with New Features - Post 2020)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "at9NHBwjAmTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, just for fun, let's add back in our original differential features."
      ],
      "metadata": {
        "id": "Rhpdiq5AD4_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize our original differential features\n",
        "def normalize_differential_features_only(df):\n",
        "    # Identify differential columns\n",
        "    diff_cols = [col for col in df.columns if col.startswith(\"Diff \") and df[col].notna().all()]\n",
        "\n",
        "    # Standardize only those columns\n",
        "    scaler = StandardScaler()\n",
        "    df[diff_cols] = scaler.fit_transform(df[diff_cols])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply normalization to both datasets\n",
        "df_pre2020 = normalize_differential_features_only(df_pre2020)\n",
        "df_post2020 = normalize_differential_features_only(df_post2020)"
      ],
      "metadata": {
        "id": "9bx27hn6Ejd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre 2020\n",
        "# 1. Define target variable\n",
        "df_pre2020['Win'] = (df_pre2020['Winner'] == df_pre2020['Team 1']).astype(int)\n",
        "#df_post2020.head()\n",
        "\n",
        "# 2. Select only differential features\n",
        "all_diff_features = [col for col in df_pre2020.columns if col.startswith(\"Diff \") and df_pre2020[col].notna().all()]\n",
        "\n",
        "diff_features = list(set(\n",
        "    [col for col in all_diff_features if 'Games Played' not in col] +\n",
        "    [\n",
        "        'T1_Offense_vs_T2_Defense', 'T2_Offense_vs_T1_Defense',\n",
        "        'T1_Turnovers_vs_T2_CausedTOs', 'T2_Turnovers_vs_T1_CausedTOs',\n",
        "        'T1_ManUp_vs_T2_ManDown', 'T2_ManUp_vs_T1_ManDown',\n",
        "        'T1_Goalie_vs_T2_Shooting', 'T2_Goalie_vs_T1_Shooting',\n",
        "        'Faceoff_Percent_Diff', 'RPI_Diff', 'Margin_Diff'\n",
        "    ]\n",
        "))\n",
        "\n",
        "# remove duplicates\n",
        "to_remove = ['RPI_Diff', 'Margin_Diff', 'Faceoff_Percent_Diff', 'Diff Saves per Game']\n",
        "diff_features = [col for col in diff_features if col not in to_remove]\n",
        "\n",
        "\n",
        "# Create X and y\n",
        "X = df_pre2020[diff_features].copy()\n",
        "y = df_pre2020['Win']\n",
        "\n",
        "# 3. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Train logistic regression\n",
        "# Train logistic regression with L2 regularization\n",
        "model_pre2020 = LogisticRegression(solver='liblinear')\n",
        "model_pre2020.fit(X_train, y_train)\n",
        "\n",
        "# 5. Evaluate model\n",
        "y_pred = model_pre2020.predict(X_test)\n",
        "accuracy_pre2020 = accuracy_score(y_test, y_pred)\n",
        "f1_pre2020 = f1_score(y_test, y_pred)\n",
        "report_pre2020 = classification_report(y_test, y_pred)\n",
        "\n",
        "# 6. Feature importance\n",
        "coefficients_pre2020 = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_pre2020.coef_[0]\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_pre2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_pre2020:.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_pre2020)\n",
        "print(coefficients_pre2020.head(10))  # Top 10 features\n",
        "print(\"\\n10 Least Influential Features:\")\n",
        "print(coefficients_pre2020.tail(10))\n",
        "\n",
        "# 8. Learning Curve\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(max_iter=1000),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plotting\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression with New Features - Pre 2020)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mSmLTtvnFv_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# post 2020\n",
        "# 1. Define target variable\n",
        "df_post2020['Win'] = (df_post2020['Winner'] == df_post2020['Team 1']).astype(int)\n",
        "#df_post2020.head()\n",
        "\n",
        "# 2. Select only differential features\n",
        "all_diff_features = [col for col in df_post2020.columns if col.startswith(\"Diff \") and df_post2020[col].notna().all()]\n",
        "\n",
        "diff_features = list(set(\n",
        "    [col for col in all_diff_features if 'Games Played' not in col] +\n",
        "    [\n",
        "        'T1_Offense_vs_T2_Defense', 'T2_Offense_vs_T1_Defense',\n",
        "        'T1_Turnovers_vs_T2_CausedTOs', 'T2_Turnovers_vs_T1_CausedTOs',\n",
        "        'T1_Clear_vs_T2_OppClear', 'T2_Clear_vs_T1_OppClear',\n",
        "        'T1_ManUp_vs_T2_ManDown', 'T2_ManUp_vs_T1_ManDown',\n",
        "        'T1_Goalie_vs_T2_Shooting', 'T2_Goalie_vs_T1_Shooting',\n",
        "        'Faceoff_Percent_Diff', 'RPI_Diff', 'Margin_Diff'\n",
        "    ]\n",
        "))\n",
        "\n",
        "# remove duplicates\n",
        "to_remove = ['RPI_Diff', 'Margin_Diff', 'Faceoff_Percent_Diff', 'Diff Saves per Game']\n",
        "diff_features = [col for col in diff_features if col not in to_remove]\n",
        "\n",
        "\n",
        "# Create X and y\n",
        "X = df_post2020[diff_features].copy()\n",
        "y = df_post2020['Win']\n",
        "\n",
        "# 3. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Train logistic regression\n",
        "# Don't use regularization\n",
        "model_post2020 = LogisticRegression(solver='liblinear')\n",
        "model_post2020.fit(X_train, y_train)\n",
        "\n",
        "# 5. Evaluate model\n",
        "y_pred = model_post2020.predict(X_test)\n",
        "accuracy_post2020 = accuracy_score(y_test, y_pred)\n",
        "f1_post2020 = f1_score(y_test, y_pred)\n",
        "report_post2020 = classification_report(y_test, y_pred)\n",
        "\n",
        "# 6. Feature importance\n",
        "coefficients_post2020 = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_post2020.coef_[0]\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_post2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_post2020:.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_post2020)\n",
        "print(coefficients_post2020.head(10))  # Top 10 features\n",
        "print(\"\\n10 Least Influential Features:\")\n",
        "print(coefficients_post2020.tail(10))\n",
        "\n",
        "# 8. Learning Curve\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(max_iter=1000),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plotting\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression with New Features - Post 2020)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2M3eXSlSEu_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is interesting. As we can see, most of the top 10 important features are still from our original list of differential features."
      ],
      "metadata": {
        "id": "MPep84pkNdBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering: Rolling Averages"
      ],
      "metadata": {
        "id": "SQUlQ-08IaEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will try to add in new statistics that could help us learn more about how a team is playing. We will add in rolling averages that will give us a sense of how much momentum each team has."
      ],
      "metadata": {
        "id": "o7WLqCQQINkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "\n",
        "# used for printing entire rows\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "zr6HgmFYItoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to CSV file\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Final Data/ncaa_lacrosse_with_RPI.csv\"\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "#print(\"dataframe size\", df.shape)"
      ],
      "metadata": {
        "id": "mFeqkJ_WIuOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normal Pre-Processing"
      ],
      "metadata": {
        "id": "DDXR_d6cJNpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add a goalie save pct (saves per game / [saves per game + goals allowed per game])\n",
        "\n",
        "# Calculate goalie save percentage for Team 1\n",
        "df['Team 1 Save Percent'] = df['Team 1 Saves per Game'] / (\n",
        "    df['Team 1 Saves per Game'] + df['Team 1 Goals Allowed per Game']\n",
        ")\n",
        "\n",
        "# Calculate goalie save percentage for Team 2\n",
        "df['Team 2 Save Percent'] = df['Team 2 Saves per Game'] / (\n",
        "    df['Team 2 Saves per Game'] + df['Team 2 Goals Allowed per Game']\n",
        ")"
      ],
      "metadata": {
        "id": "eA1KfM0bJ3wP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the game count\n",
        "\n",
        "# Ensure Date is a datetime object\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Sort by date to ensure correct game order\n",
        "df = df.sort_values(by='Date').reset_index(drop=True)\n",
        "\n",
        "# Function to count games per team up to each date\n",
        "def add_game_counts(df):\n",
        "    team_game_counts = {}\n",
        "\n",
        "    game_counts = []\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        df['Year'] = df['Date'].dt.year\n",
        "        year = row['Year']\n",
        "        team1 = row['Team 1']\n",
        "        team2 = row['Team 2']\n",
        "        date = row['Date']\n",
        "\n",
        "        # Create keys based on year and team\n",
        "        key1 = (year, team1)\n",
        "        key2 = (year, team2)\n",
        "\n",
        "        # Get current game count\n",
        "        count1 = team_game_counts.get(key1, 0)\n",
        "        count2 = team_game_counts.get(key2, 0)\n",
        "\n",
        "        game_counts.append((count1, count2))\n",
        "\n",
        "        # Increment game counts AFTER the game\n",
        "        team_game_counts[key1] = count1 + 1\n",
        "        team_game_counts[key2] = count2 + 1\n",
        "\n",
        "    df['Team 1 Games Played'] = [c[0] for c in game_counts]\n",
        "    df['Team 2 Games Played'] = [c[1] for c in game_counts]\n",
        "\n",
        "    return df\n",
        "\n",
        "# Add game counts\n",
        "df = add_game_counts(df)\n",
        "\n",
        "# we will filter after we compute the rolling averages\n",
        "\n",
        "# Preview cleaned data\n",
        "#df.head()\n",
        "\n",
        "#print(\"dataframe size\", df.shape)\n"
      ],
      "metadata": {
        "id": "syexUVQAJGlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove games with a 0-0 score (invalid data)\n",
        "df = df[~((df['Score 1'] == 0) & (df['Score 2'] == 0))]\n",
        "\n",
        "# Optional: reset index after filtering\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "#print(\"dataframe size\", df.shape)"
      ],
      "metadata": {
        "id": "IBMEQKpoJGnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing Rolling Averages"
      ],
      "metadata": {
        "id": "XQhBhWtmN5cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we comtinue preprocessing the data, we need to compute rolling averages. Before we do this, we will need a function to help us test it."
      ],
      "metadata": {
        "id": "9fu0Wvy5Jhe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is a testing function, it prints given statistics from the entire given year for the given team\n",
        "def get_team_season_subset(name, year, df, columns_to_print):\n",
        "    subset = df[((df['Team 1'] == name) | (df['Team 2'] == name)) & (df['Year'] == year)]\n",
        "    return subset[columns_to_print]\n",
        "\n",
        "\n",
        "# Example: Get 2022 data for 'duke'\n",
        "'''\n",
        "columns_to_view = ['Date', 'Team 1', 'Team 2', 'Score 1', 'Score 2',\n",
        "                   ]\n",
        "subset = get_team_season_subset('duke', 2024, df, columns_to_view)\n",
        "subset = subset.sort_values(by='Date')\n",
        "print(subset)\n",
        "'''"
      ],
      "metadata": {
        "id": "bl2jXYl4JGqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to compute rolling averages, we need to add in total statistic features for each statistic. This can be found by multiplying the games played by the average for that statistic."
      ],
      "metadata": {
        "id": "dgBwMY7POBPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_total_stats(df, stat_suffixes):\n",
        "    \"\"\"\n",
        "    Compute total stats for Team 1 and Team 2 for given stat suffixes.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): Input DataFrame.\n",
        "        stat_suffixes (list of str): e.g., [\"Goals per Game\", \"Shots per Game\"]\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with total stat columns added.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    for team in [\"Team 1\", \"Team 2\"]:\n",
        "        games_played_col = f\"{team} Games Played\"\n",
        "\n",
        "        for stat_suffix in stat_suffixes:\n",
        "            avg_col = f\"{team} {stat_suffix}\"\n",
        "            total_col = f\"{avg_col} Total\"\n",
        "            df[total_col] = df[avg_col] * df[games_played_col]\n",
        "\n",
        "    return df\n",
        "\n",
        "#df = compute_total_stats(df, [\"Assists per Game\", 'Clearing Percent'])"
      ],
      "metadata": {
        "id": "QZm8h4XsTfZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to compute rolling averages, you need to take the total from current game and subtract it from the total from the previous game (or however many games ago your window is), and then divide this by the games in that window. In order to do this, I made a helper function to get the previous statistic based on a window."
      ],
      "metadata": {
        "id": "E4NVZVLbObyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is a function to get the previous statistic\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def get_stat_from_nth_previous_game(team_name: str, date, df: pd.DataFrame, window: int, column_name: str):\n",
        "    # Ensure Date is datetime\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    date = pd.to_datetime(date)\n",
        "    year = date.year\n",
        "\n",
        "    # Filter games in the same year with the team\n",
        "    year_games = df[\n",
        "        ((df['Team 1'] == team_name) | (df['Team 2'] == team_name)) &\n",
        "        (df['Date'].dt.year == year)\n",
        "    ].copy()\n",
        "\n",
        "    # Games before or on the date\n",
        "    past_games = year_games[year_games['Date'] <= date].sort_values(by='Date', ascending=False)\n",
        "\n",
        "    # Try to get the nth previous game\n",
        "    if len(past_games) >= window:\n",
        "        candidate_game = past_games.iloc[window - 1]\n",
        "    else:\n",
        "        # Fallback to first game of the year\n",
        "        sorted_games = year_games.sort_values(by='Date')\n",
        "        if not sorted_games.empty:\n",
        "            candidate_game = sorted_games.iloc[0]\n",
        "        else:\n",
        "            return np.nan  # No games at all that year\n",
        "\n",
        "    # Determine the correct column\n",
        "    if candidate_game['Team 1'] == team_name:\n",
        "        stat_column = f'Team 1 {column_name}'\n",
        "    elif candidate_game['Team 2'] == team_name:\n",
        "        stat_column = f'Team 2 {column_name}'\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "    # If value is missing, search forward for next non-NaN\n",
        "    if pd.isna(candidate_game.get(stat_column)):\n",
        "        future_games = year_games[year_games['Date'] > candidate_game['Date']].sort_values(by='Date')\n",
        "\n",
        "        for _, row in future_games.iterrows():\n",
        "            if row['Team 1'] == team_name:\n",
        "                stat_col = f'Team 1 {column_name}'\n",
        "            elif row['Team 2'] == team_name:\n",
        "                stat_col = f'Team 2 {column_name}'\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            value = row.get(stat_col)\n",
        "            if not pd.isna(value):\n",
        "                return value\n",
        "\n",
        "        return np.nan  # Still no valid value found\n",
        "\n",
        "    return candidate_game.get(stat_column)\n",
        "\n",
        "value = get_stat_from_nth_previous_game(\"lafayette\", \"2024-03-24\", df, 100, \"Goals per Game\")\n",
        "print(\"Stat value:\", value)"
      ],
      "metadata": {
        "id": "yoT1YnR-UPup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function actually computes all of the rolling averages for the entire dataframe."
      ],
      "metadata": {
        "id": "aE7ajoD_Ov3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_rolling_avg_from_totals(df, stat_suffixes, window):\n",
        "    \"\"\"\n",
        "    Compute rolling averages from total stats using difference between current and N-games-ago totals.\n",
        "    Adjusts denominator when fewer than 'window' games are available.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): Input DataFrame\n",
        "        stat_suffixes (list of str): e.g., [\"Goals per Game\"]\n",
        "        window (int): Rolling window size\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Updated DataFrame with rolling average columns.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "    for team_col in [\"Team 1\", \"Team 2\"]:\n",
        "        games_col = f\"{team_col} Games Played\"\n",
        "\n",
        "        for stat_suffix in stat_suffixes:\n",
        "            total_col = f\"{team_col} {stat_suffix} Total\"\n",
        "            rolling_col = f\"{team_col} {stat_suffix} RollingAvg_{window}\"\n",
        "\n",
        "            rolling_avgs = []\n",
        "\n",
        "            for _, row in df.iterrows():\n",
        "                team_name = row[team_col]\n",
        "                date = row['Date']\n",
        "                current_total = row.get(total_col)\n",
        "                current_games_played = row.get(games_col)\n",
        "\n",
        "                # because this function returns the first available number, if the window is greater than games played, just return 0\n",
        "                if (window >= current_games_played):\n",
        "                    prev_total = 0\n",
        "                else:\n",
        "                    prev_total = get_stat_from_nth_previous_game(\n",
        "                        team_name=team_name,\n",
        "                        date=date,\n",
        "                        df=df,\n",
        "                        window=window + 1,\n",
        "                        column_name=f\"{stat_suffix} Total\"\n",
        "                    )\n",
        "\n",
        "                if pd.notna(current_total) and pd.notna(prev_total) and pd.notna(current_games_played):\n",
        "                    games_in_window = min(window, current_games_played)\n",
        "                    if games_in_window > 0:\n",
        "                        rolling_avg = (current_total - prev_total) / games_in_window\n",
        "                    else:\n",
        "                        rolling_avg = np.nan\n",
        "                else:\n",
        "                    rolling_avg = np.nan\n",
        "\n",
        "                rolling_avgs.append(rolling_avg)\n",
        "\n",
        "            df[rolling_col] = rolling_avgs\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "7NzTkaffgSZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = compute_rolling_avg_from_totals(df, [\"Goals per Game\"], window=3)\n",
        "\n",
        "totals_features = [\n",
        "    'Assists per Game', 'Caused Turnovers per Game', 'Clearing Percent', 'Faceoff Percent', 'Groundballs per Game', 'Man Down Defense Percent', 'Man Up Offense Percent', 'Opponent Clear Percent',\n",
        "    'Goals per Game', 'Goals Allowed per Game', 'Average Margin', 'Shot Percent', 'Turnovers per Game', 'Save Percent', 'RPI'\n",
        "]\n",
        "\n",
        "# first, calculate the total stats\n",
        "df = compute_total_stats(df, totals_features)\n",
        "\n",
        "df = compute_rolling_avg_from_totals(df, totals_features, window=3)\n",
        "\n",
        "# Save to Google Drive so we don't have to re do\n",
        "save_path = \"/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Final Data/ncaa_lacrosse_with_RPI_rolling3.csv\"\n",
        "df.to_csv(save_path, index=False)"
      ],
      "metadata": {
        "id": "O34xSRE5gSc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PU1SNvebbTN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is some code that helped me test that it worked."
      ],
      "metadata": {
        "id": "tirX19gWO6yO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Example: Get 2022 data for 'duke', showing rolling goal stats and game date\n",
        "#columns_to_view = ['Date', 'Team 1', 'Team 2', 'Score 1', 'Score 2', 'Team 1 Assists per Game', 'Team 2 Assists per Game',\n",
        "                   #'Team 1 Assists per Game Total', 'Team 2 Assists per Game Total', 'Team 1 Assists per Game RollingAvg_3', 'Team 2 Assists per Game RollingAvg_3'\n",
        "                   #]\n",
        "\n",
        "columns_to_view = ['Date', 'Team 1', 'Team 2', 'Score 1', 'Score 2', 'Team 1 Clearing Percent', 'Team 2 Clearing Percent',\n",
        "                   'Team 1 Clearing Percent Total', 'Team 2 Clearing Percent Total', 'Team 1 Clearing Percent RollingAvg_3', 'Team 2 Clearing Percent RollingAvg_3'\n",
        "                   ]\n",
        "subset = get_team_season_subset('lafayette', 2024, df, columns_to_view)\n",
        "subset = subset.sort_values(by='Date')\n",
        "print(subset)\n",
        "'''\n"
      ],
      "metadata": {
        "id": "QEz7e1NDUPxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Example: Get 2022 data for 'duke', showing rolling goal stats and game date\n",
        "columns_to_view = ['Date', 'Team 1', 'Team 2', 'Score 1', 'Score 2', 'Team 1 Goals per Game', 'Team 2 Goals per Game', 'Team 1 Goals per Game RollingAvg_3', 'Team 2 Goals per Game RollingAvg_3'\n",
        "                   ]\n",
        "subset = get_team_season_subset('lafayette', 2024, df, columns_to_view)\n",
        "subset = subset.sort_values(by='Date')\n",
        "print(subset)\n",
        "'''"
      ],
      "metadata": {
        "id": "hzIvLmFEL3WB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression on Rolling Stats"
      ],
      "metadata": {
        "id": "sOZ3KcypD2B6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-Process the Data"
      ],
      "metadata": {
        "id": "6SpOpGD3Pbhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "8XKwWlQ0EM2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in our dataset\n",
        "# Define the path to your CSV file\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Final Data/ncaa_lacrosse_with_RPI_rolling3.csv\"\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "lo6U_hAREM2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# games played is already in the data, just need to filter\n",
        "\n",
        "# Filter: keep only games where both teams have played at least 2 games before this one\n",
        "df = df[(df['Team 1 Games Played'] >= 2) & (df['Team 2 Games Played'] >= 2)]\n",
        "\n",
        "# Preview cleaned data\n",
        "#df.head()\n",
        "\n",
        "print(df.shape)\n"
      ],
      "metadata": {
        "id": "eRlMRLgwEM2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove games with a 0-0 score (invalid data)\n",
        "df = df[~((df['Score 1'] == 0) & (df['Score 2'] == 0))]\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "XArU8ysEEM2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of Opponent Clear Percent columns to exclude from NaN filtering\n",
        "excluded_columns = ['Team 1 Opponent Clear Percent', 'Team 2 Opponent Clear Percent', 'Team 1 Opponent Clear Percent RollingAvg_3', 'Team 2 Opponent Clear Percent RollingAvg_3', 'Team 1 Opponent Clear Percent Total', 'Team 2 Opponent Clear Percent Total']\n",
        "\n",
        "# Columns to check for NaNs (all except excluded ones)\n",
        "columns_to_check = [col for col in df.columns if col not in excluded_columns]\n",
        "\n",
        "# Drop rows with NaNs in any of those columns\n",
        "df = df.dropna(subset=columns_to_check).reset_index(drop=True)\n",
        "\n",
        "# Preview cleaned data\n",
        "#df.head()\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "vGT1Z2KnEM2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset by year so I can do the same thing to opponent clear percentage AFTER 2020\n",
        "df_pre2020 = df[(df['Year'] >= 2015) & (df['Year'] <= 2019)].copy()\n",
        "df_post2020 = df[(df['Year'] >= 2020) & (df['Year'] <= 2024)].copy()\n",
        "\n",
        "\n",
        "# Check sizes\n",
        "print(\"Pre-2020 dataset shape:\", df_pre2020.shape)\n",
        "print(\"2020+ dataset shape:\", df_post2020.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "L3cQwlfzEM2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop NaN in opponent clear percentage for post 2020\n",
        "df_post2020 = df_post2020.dropna(subset=['Team 1 Opponent Clear Percent', 'Team 2 Opponent Clear Percent', 'Team 1 Opponent Clear Percent RollingAvg_3', 'Team 2 Opponent Clear Percent RollingAvg_3', 'Team 1 Opponent Clear Percent Total', 'Team 2 Opponent Clear Percent Total']).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "mxrnG10vEM2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pre-2020 dataset shape:\", df_pre2020.shape)\n",
        "print(\"2020+ dataset shape:\", df_post2020.shape)"
      ],
      "metadata": {
        "id": "rw-kzbvDEM2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to create differential features for this dataset. Since we have so many features now, this will take some more code."
      ],
      "metadata": {
        "id": "_hckwi0fF7bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify matching statistic pairs\n",
        "team1_prefix = \"Team 1 \"\n",
        "team2_prefix = \"Team 2 \"\n",
        "\n",
        "# Collect column pairs for which both Team 1 and Team 2 have values\n",
        "stat_columns = [\n",
        "    ('Team 1 Assists per Game', 'Team 2 Assists per Game'),\n",
        "    ('Team 1 Caused Turnovers per Game', 'Team 2 Caused Turnovers per Game'),\n",
        "    ('Team 1 Clearing Percent', 'Team 2 Clearing Percent'),\n",
        "    ('Team 1 Faceoff Percent', 'Team 2 Faceoff Percent'),\n",
        "    ('Team 1 Groundballs per Game', 'Team 2 Groundballs per Game'),\n",
        "    ('Team 1 Man Down Defense Percent', 'Team 2 Man Down Defense Percent'),\n",
        "    ('Team 1 Man Up Offense Percent', 'Team 2 Man Up Offense Percent'),\n",
        "    ('Team 1 Opponent Clear Percent', 'Team 2 Opponent Clear Percent'),\n",
        "    ('Team 1 Goals per Game', 'Team 2 Goals per Game'),\n",
        "    ('Team 1 Saves per Game', 'Team 2 Saves per Game'),\n",
        "    ('Team 1 Goals Allowed per Game', 'Team 2 Goals Allowed per Game'),\n",
        "    ('Team 1 Average Margin', 'Team 2 Average Margin'),\n",
        "    ('Team 1 Shot Percent', 'Team 2 Shot Percent'),\n",
        "    ('Team 1 Turnovers per Game', 'Team 2 Turnovers per Game'),\n",
        "    ('Team 1 RPI', 'Team 2 RPI'),\n",
        "    ('Team 1 Save Percent', 'Team 2 Save Percent'),\n",
        "    ('Team 1 Games Played', 'Team 2 Games Played'),\n",
        "    ('Team 1 Assists per Game RollingAvg_3', 'Team 2 Assists per Game RollingAvg_3'),\n",
        "    ('Team 1 Caused Turnovers per Game RollingAvg_3', 'Team 2 Caused Turnovers per Game RollingAvg_3'),\n",
        "    ('Team 1 Clearing Percent RollingAvg_3', 'Team 2 Clearing Percent RollingAvg_3'),\n",
        "    ('Team 1 Faceoff Percent RollingAvg_3', 'Team 2 Faceoff Percent RollingAvg_3'),\n",
        "    ('Team 1 Groundballs per Game RollingAvg_3', 'Team 2 Groundballs per Game RollingAvg_3'),\n",
        "    ('Team 1 Man Down Defense Percent RollingAvg_3', 'Team 2 Man Down Defense Percent RollingAvg_3'),\n",
        "    ('Team 1 Man Up Offense Percent RollingAvg_3', 'Team 2 Man Up Offense Percent RollingAvg_3'),\n",
        "    ('Team 1 Opponent Clear Percent RollingAvg_3', 'Team 2 Opponent Clear Percent RollingAvg_3'),\n",
        "    ('Team 1 Goals per Game RollingAvg_3', 'Team 2 Goals per Game RollingAvg_3'),\n",
        "    ('Team 1 Goals Allowed per Game RollingAvg_3', 'Team 2 Goals Allowed per Game RollingAvg_3'),\n",
        "    ('Team 1 Average Margin RollingAvg_3', 'Team 2 Average Margin RollingAvg_3'),\n",
        "    ('Team 1 Shot Percent RollingAvg_3', 'Team 2 Shot Percent RollingAvg_3'),\n",
        "    ('Team 1 Turnovers per Game RollingAvg_3', 'Team 2 Turnovers per Game RollingAvg_3'),\n",
        "    ('Team 1 Save Percent RollingAvg_3', 'Team 2 Save Percent RollingAvg_3'),\n",
        "    ('Team 1 RPI RollingAvg_3', 'Team 2 RPI RollingAvg_3')\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Function to compute differential features\n",
        "def add_differential_features(df, stat_columns):\n",
        "    for t1_col, t2_col in stat_columns:\n",
        "        diff_col = \"Diff \" + t1_col[len(team1_prefix):]\n",
        "        df[diff_col] = df[t1_col] - df[t2_col]\n",
        "    return df\n",
        "\n",
        "# Apply to both datasets\n",
        "df_pre2020 = add_differential_features(df_pre2020, stat_columns)\n",
        "df_post2020 = add_differential_features(df_post2020, stat_columns)\n",
        "\n",
        "# Preview updated data\n",
        "df_pre2020[[col for col in df_pre2020.columns if col.startswith(\"Diff\")]].head()\n"
      ],
      "metadata": {
        "id": "7Dy2NTXSGDhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's normalize our data."
      ],
      "metadata": {
        "id": "OTifAV30H6-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_differential_features_only(df):\n",
        "    # Identify differential columns\n",
        "    diff_cols = [col for col in df.columns if col.startswith(\"Diff \") and df[col].notna().all()]\n",
        "\n",
        "    # Standardize only those columns\n",
        "    scaler = StandardScaler()\n",
        "    df[diff_cols] = scaler.fit_transform(df[diff_cols])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply normalization to both datasets\n",
        "df_pre2020 = normalize_differential_features_only(df_pre2020)\n",
        "df_post2020 = normalize_differential_features_only(df_post2020)"
      ],
      "metadata": {
        "id": "V4jAitHBD7nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running Logistic Regression"
      ],
      "metadata": {
        "id": "iPqpwZ7MPmBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's run the actual logistic regression for both pre and post 2020"
      ],
      "metadata": {
        "id": "-wBAjMDFIKWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from sklearn.model_selection import train_test_split, learning_curve\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, make_scorer, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "J8zqHLQ_Ikww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define target variable\n",
        "df_pre2020['Win'] = (df_pre2020['Winner'] == df_pre2020['Team 1']).astype(int)\n",
        "\n",
        "# 2. Select only differential features\n",
        "all_diff_features = [col for col in df_pre2020.columns if col.startswith(\"Diff \") and df_pre2020[col].notna().all()]\n",
        "diff_features = [col for col in all_diff_features if 'Games Played' not in col]\n",
        "\n",
        "# 3. Create X and y\n",
        "X = df_pre2020[diff_features].copy()\n",
        "y = df_pre2020['Win']\n",
        "\n",
        "# 4. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Train logistic regression\n",
        "model_pre2020 = LogisticRegression(max_iter=1000)\n",
        "model_pre2020.fit(X_train, y_train)\n",
        "\n",
        "# 6. Evaluate model\n",
        "y_pred = model_pre2020.predict(X_test)\n",
        "accuracy_pre2020 = accuracy_score(y_test, y_pred)\n",
        "f1_pre2020 = f1_score(y_test, y_pred)\n",
        "report_pre2020 = classification_report(y_test, y_pred)\n",
        "\n",
        "# 7. Feature importance\n",
        "coefficients_pre2020 = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_pre2020.coef_[0]\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_pre2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_pre2020:.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_pre2020)\n",
        "print(\"\\nTop 10 Most Influential Features:\")\n",
        "print(coefficients_pre2020.head(10))  # Top 10 features\n",
        "print(\"\\n10 Least Influential Features:\")\n",
        "print(coefficients_pre2020.tail(10))\n",
        "\n",
        "# 8. Plot learning curve\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(max_iter=1000),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plotting\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression with Rolling Averages - Pre 2020)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "82R0oBJ_D7ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define target variable\n",
        "df_post2020['Win'] = (df_post2020['Winner'] == df_post2020['Team 1']).astype(int)\n",
        "\n",
        "# 2. Select only differential features\n",
        "all_diff_features = [col for col in df_post2020.columns if col.startswith(\"Diff \") and df_post2020[col].notna().all()]\n",
        "diff_features = [col for col in all_diff_features if 'Games Played' not in col]\n",
        "\n",
        "# Create X and y\n",
        "X = df_post2020[diff_features].copy()\n",
        "y = df_post2020['Win']\n",
        "\n",
        "# 3. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Train logistic regression\n",
        "model_post2020 = LogisticRegression(max_iter=1000)\n",
        "model_post2020.fit(X_train, y_train)\n",
        "\n",
        "# 5. Evaluate model\n",
        "y_pred = model_post2020.predict(X_test)\n",
        "accuracy_post2020 = accuracy_score(y_test, y_pred)\n",
        "f1_post2020 = f1_score(y_test, y_pred)\n",
        "report_post2020 = classification_report(y_test, y_pred)\n",
        "\n",
        "# 6. Feature importance\n",
        "coefficients_post2020 = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_post2020.coef_[0]\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_post2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_post2020:.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_post2020)\n",
        "print(\"\\nTop 10 Most Influential Features:\")\n",
        "print(coefficients_post2020.head(10))  # Top 10 features\n",
        "print(\"\\n10 Least Influential Features:\")\n",
        "print(coefficients_post2020.tail(10))\n",
        "\n",
        "# 7. Plot learning curve (on full dataset)\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(max_iter=1000),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 8. Compute means and standard deviations\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plot learning curve\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression with Rolling Averages - Post 2020)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KxooutGJKjLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will try to run a logistic regression with just the new data."
      ],
      "metadata": {
        "id": "YNyBeGa3PSqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from sklearn.model_selection import train_test_split, learning_curve\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, make_scorer, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Rqye1siXPi0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define target variable\n",
        "df_pre2020['Win'] = (df_pre2020['Winner'] == df_pre2020['Team 1']).astype(int)\n",
        "\n",
        "# 2. Select only differential features THAT ALSO are rolling averages\n",
        "diff_features = [\n",
        "    col for col in df_pre2020.columns  # <-- note we're using df_pre2020 here now\n",
        "    if col.startswith(\"Diff \") and\n",
        "       \"RollingAvg_3\" in col and\n",
        "       \"Games Played\" not in col and\n",
        "       df_pre2020[col].notna().all()\n",
        "]\n",
        "\n",
        "\n",
        "# 3. Create X and y\n",
        "X = df_pre2020[diff_features].copy()\n",
        "y = df_pre2020['Win']\n",
        "\n",
        "# 4. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Train logistic regression\n",
        "model_pre2020 = LogisticRegression(max_iter=1000)\n",
        "model_pre2020.fit(X_train, y_train)\n",
        "\n",
        "# 6. Evaluate model\n",
        "y_pred = model_pre2020.predict(X_test)\n",
        "accuracy_pre2020 = accuracy_score(y_test, y_pred)\n",
        "f1_pre2020 = f1_score(y_test, y_pred)\n",
        "report_pre2020 = classification_report(y_test, y_pred)\n",
        "\n",
        "# 7. Feature importance\n",
        "coefficients_pre2020 = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_pre2020.coef_[0]\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_pre2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred):.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_pre2020)\n",
        "print(\"\\nTop 10 Most Influential Features:\")\n",
        "print(coefficients_pre2020.head(10))  # Top 10 features\n",
        "print(\"\\n10 Least Influential Features:\")\n",
        "print(coefficients_pre2020.tail(10))\n",
        "\n",
        "# 8. Plot learning curve\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(max_iter=1000),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plotting\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression with Rolling Averages Only - Pre 2020)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "udNQ7nmmPqqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# post 2020\n",
        "# 1. Define target variable\n",
        "df_post2020['Win'] = (df_post2020['Winner'] == df_post2020['Team 1']).astype(int)\n",
        "\n",
        "# 2. Select only differential features THAT ALSO are rolling averages\n",
        "diff_features = [\n",
        "    col for col in df_pre2020.columns  # <-- note we're using df_pre2020 here now\n",
        "    if col.startswith(\"Diff \") and\n",
        "       \"RollingAvg_3\" in col and\n",
        "       \"Games Played\" not in col and\n",
        "       df_pre2020[col].notna().all()\n",
        "]\n",
        "\n",
        "# Create X and y\n",
        "X = df_post2020[diff_features].copy()\n",
        "y = df_post2020['Win']\n",
        "\n",
        "# 3. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Train logistic regression\n",
        "model_post2020 = LogisticRegression(max_iter=1000)\n",
        "model_post2020.fit(X_train, y_train)\n",
        "\n",
        "# 5. Evaluate model\n",
        "y_pred = model_post2020.predict(X_test)\n",
        "accuracy_post2020 = accuracy_score(y_test, y_pred)\n",
        "f1_post2020 = f1_score(y_test, y_pred)\n",
        "report_post2020 = classification_report(y_test, y_pred)\n",
        "\n",
        "# 6. Feature importance\n",
        "coefficients_post2020 = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_post2020.coef_[0]\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_post2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred):.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_post2020)\n",
        "print(\"\\nTop 10 Most Influential Features:\")\n",
        "print(coefficients_post2020.head(10))  # Top 10 features\n",
        "print(\"\\n10 Least Influential Features:\")\n",
        "print(coefficients_post2020.tail(10))\n",
        "\n",
        "\n",
        "# 7. Plot learning curve (on full dataset)\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(max_iter=1000),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 8. Compute means and standard deviations\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plot learning curve\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression with Rolling Averages Only - Post 2020)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_VZBzlwiRNn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regularization"
      ],
      "metadata": {
        "id": "7IWjUVfsSvGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It appears that the data with both season totals AND rolling averages performs the best. I am going run this with regularization. First, we need to re load the data."
      ],
      "metadata": {
        "id": "fmXnV0EfRiYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pre-Process the Data"
      ],
      "metadata": {
        "id": "v7ht5ZXYTMow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "Z52jJWF_Yj0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in our dataset\n",
        "# Define the path to your CSV file\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Final Project Real Folder/Final Data/ncaa_lacrosse_with_RPI_rolling3.csv\"\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "ak89hLWtYj0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# games played is already in the data, just need to filter\n",
        "\n",
        "# Filter: keep only games where both teams have played at least 2 games before this one\n",
        "df = df[(df['Team 1 Games Played'] >= 2) & (df['Team 2 Games Played'] >= 2)]\n",
        "\n",
        "# Preview cleaned data\n",
        "#df.head()\n",
        "\n",
        "print(df.shape)\n"
      ],
      "metadata": {
        "id": "oF5g0-RIYj0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove games with a 0-0 score (invalid data)\n",
        "df = df[~((df['Score 1'] == 0) & (df['Score 2'] == 0))]\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "QpmJaRSSYj0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of Opponent Clear Percent columns to exclude from NaN filtering\n",
        "excluded_columns = ['Team 1 Opponent Clear Percent', 'Team 2 Opponent Clear Percent', 'Team 1 Opponent Clear Percent RollingAvg_3', 'Team 2 Opponent Clear Percent RollingAvg_3', 'Team 1 Opponent Clear Percent Total', 'Team 2 Opponent Clear Percent Total']\n",
        "\n",
        "# Columns to check for NaNs (all except excluded ones)\n",
        "columns_to_check = [col for col in df.columns if col not in excluded_columns]\n",
        "\n",
        "# Drop rows with NaNs in any of those columns\n",
        "df = df.dropna(subset=columns_to_check).reset_index(drop=True)\n",
        "\n",
        "# Preview cleaned data\n",
        "#df.head()\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "GGbgBjkdYj0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset by year so I can do the same thing to opponent clear percentage AFTER 2020\n",
        "df_pre2020 = df[(df['Year'] >= 2015) & (df['Year'] <= 2019)].copy()\n",
        "df_post2020 = df[(df['Year'] >= 2020) & (df['Year'] <= 2024)].copy()\n",
        "\n",
        "\n",
        "# Check sizes\n",
        "print(\"Pre-2020 dataset shape:\", df_pre2020.shape)\n",
        "print(\"2020+ dataset shape:\", df_post2020.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "fi5u2HQGYj0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop NaN in opponent clear percentage for post 2020\n",
        "df_post2020 = df_post2020.dropna(subset=['Team 1 Opponent Clear Percent', 'Team 2 Opponent Clear Percent', 'Team 1 Opponent Clear Percent RollingAvg_3', 'Team 2 Opponent Clear Percent RollingAvg_3', 'Team 1 Opponent Clear Percent Total', 'Team 2 Opponent Clear Percent Total']).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "Uxpj_xGIYj0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pre-2020 dataset shape:\", df_pre2020.shape)\n",
        "print(\"2020+ dataset shape:\", df_post2020.shape)"
      ],
      "metadata": {
        "id": "TjV7FnzzYj0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify matching statistic pairs\n",
        "team1_prefix = \"Team 1 \"\n",
        "team2_prefix = \"Team 2 \"\n",
        "\n",
        "# Collect column pairs for which both Team 1 and Team 2 have values\n",
        "stat_columns = [\n",
        "    ('Team 1 Assists per Game', 'Team 2 Assists per Game'),\n",
        "    ('Team 1 Caused Turnovers per Game', 'Team 2 Caused Turnovers per Game'),\n",
        "    ('Team 1 Clearing Percent', 'Team 2 Clearing Percent'),\n",
        "    ('Team 1 Faceoff Percent', 'Team 2 Faceoff Percent'),\n",
        "    ('Team 1 Groundballs per Game', 'Team 2 Groundballs per Game'),\n",
        "    ('Team 1 Man Down Defense Percent', 'Team 2 Man Down Defense Percent'),\n",
        "    ('Team 1 Man Up Offense Percent', 'Team 2 Man Up Offense Percent'),\n",
        "    ('Team 1 Opponent Clear Percent', 'Team 2 Opponent Clear Percent'),\n",
        "    ('Team 1 Goals per Game', 'Team 2 Goals per Game'),\n",
        "    ('Team 1 Saves per Game', 'Team 2 Saves per Game'),\n",
        "    ('Team 1 Goals Allowed per Game', 'Team 2 Goals Allowed per Game'),\n",
        "    ('Team 1 Average Margin', 'Team 2 Average Margin'),\n",
        "    ('Team 1 Shot Percent', 'Team 2 Shot Percent'),\n",
        "    ('Team 1 Turnovers per Game', 'Team 2 Turnovers per Game'),\n",
        "    ('Team 1 RPI', 'Team 2 RPI'),\n",
        "    ('Team 1 Save Percent', 'Team 2 Save Percent'),\n",
        "    ('Team 1 Games Played', 'Team 2 Games Played'),\n",
        "    ('Team 1 Assists per Game RollingAvg_3', 'Team 2 Assists per Game RollingAvg_3'),\n",
        "    ('Team 1 Caused Turnovers per Game RollingAvg_3', 'Team 2 Caused Turnovers per Game RollingAvg_3'),\n",
        "    ('Team 1 Clearing Percent RollingAvg_3', 'Team 2 Clearing Percent RollingAvg_3'),\n",
        "    ('Team 1 Faceoff Percent RollingAvg_3', 'Team 2 Faceoff Percent RollingAvg_3'),\n",
        "    ('Team 1 Groundballs per Game RollingAvg_3', 'Team 2 Groundballs per Game RollingAvg_3'),\n",
        "    ('Team 1 Man Down Defense Percent RollingAvg_3', 'Team 2 Man Down Defense Percent RollingAvg_3'),\n",
        "    ('Team 1 Man Up Offense Percent RollingAvg_3', 'Team 2 Man Up Offense Percent RollingAvg_3'),\n",
        "    ('Team 1 Opponent Clear Percent RollingAvg_3', 'Team 2 Opponent Clear Percent RollingAvg_3'),\n",
        "    ('Team 1 Goals per Game RollingAvg_3', 'Team 2 Goals per Game RollingAvg_3'),\n",
        "    ('Team 1 Goals Allowed per Game RollingAvg_3', 'Team 2 Goals Allowed per Game RollingAvg_3'),\n",
        "    ('Team 1 Average Margin RollingAvg_3', 'Team 2 Average Margin RollingAvg_3'),\n",
        "    ('Team 1 Shot Percent RollingAvg_3', 'Team 2 Shot Percent RollingAvg_3'),\n",
        "    ('Team 1 Turnovers per Game RollingAvg_3', 'Team 2 Turnovers per Game RollingAvg_3'),\n",
        "    ('Team 1 Save Percent RollingAvg_3', 'Team 2 Save Percent RollingAvg_3'),\n",
        "    ('Team 1 RPI RollingAvg_3', 'Team 2 RPI RollingAvg_3')\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Function to compute differential features\n",
        "def add_differential_features(df, stat_columns):\n",
        "    for t1_col, t2_col in stat_columns:\n",
        "        diff_col = \"Diff \" + t1_col[len(team1_prefix):]\n",
        "        df[diff_col] = df[t1_col] - df[t2_col]\n",
        "    return df\n",
        "\n",
        "# Apply to both datasets\n",
        "df_pre2020 = add_differential_features(df_pre2020, stat_columns)\n",
        "df_post2020 = add_differential_features(df_post2020, stat_columns)\n",
        "\n",
        "# Preview updated data\n",
        "df_pre2020[[col for col in df_pre2020.columns if col.startswith(\"Diff\")]].head()\n"
      ],
      "metadata": {
        "id": "gSDJIOwkYj0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_differential_features_only(df):\n",
        "    # Identify differential columns\n",
        "    diff_cols = [col for col in df.columns if col.startswith(\"Diff \") and df[col].notna().all()]\n",
        "\n",
        "    # Standardize only those columns\n",
        "    scaler = StandardScaler()\n",
        "    df[diff_cols] = scaler.fit_transform(df[diff_cols])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply normalization to both datasets\n",
        "df_pre2020 = normalize_differential_features_only(df_pre2020)\n",
        "df_post2020 = normalize_differential_features_only(df_post2020)"
      ],
      "metadata": {
        "id": "A-oyQ023Yj0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Running Logistic Regression with L1 Regularization"
      ],
      "metadata": {
        "id": "xB6MpGXHc71p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, learning_curve\n",
        "from sklearn.metrics import classification_report, accuracy_score, make_scorer, f1_score"
      ],
      "metadata": {
        "id": "XM729r5WTsC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre 2020\n",
        "\n",
        "# 1. Define target variable\n",
        "df_pre2020['Win'] = (df_pre2020['Winner'] == df_pre2020['Team 1']).astype(int)\n",
        "\n",
        "# 2. Select only differential features (rolling averages only)\n",
        "all_diff_features = [col for col in df_pre2020.columns if col.startswith(\"Diff \") and df_pre2020[col].notna().all()]\n",
        "diff_features = [col for col in all_diff_features if 'Games Played' not in col]\n",
        "\n",
        "# 3. Create X and y\n",
        "X = df_pre2020[diff_features].copy()\n",
        "y = df_pre2020['Win']\n",
        "\n",
        "# 4. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Train logistic regression with L1 regularization\n",
        "model_pre2020 = LogisticRegression(penalty='l1', solver='liblinear', C=0.5, max_iter=1000)\n",
        "model_pre2020.fit(X_train, y_train)\n",
        "\n",
        "# 6. Evaluate model\n",
        "y_pred = model_pre2020.predict(X_test)\n",
        "accuracy_pre2020 = accuracy_score(y_test, y_pred)\n",
        "f1_pre2020 = f1_score(y_test, y_pred)\n",
        "report_pre2020 = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_pre2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred):.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_pre2020)\n",
        "\n",
        "# 7. Feature importance\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_pre2020.coef_[0]\n",
        "})\n",
        "\n",
        "# Top 10 most important\n",
        "top_features = coef_df.reindex(coef_df['Coefficient'].abs().sort_values(ascending=False).index).head(10)\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(top_features)\n",
        "\n",
        "# Bottom 10 least important (including zeros)\n",
        "bottom_features = coef_df.reindex(coef_df['Coefficient'].abs().sort_values(ascending=True).index).head(10)\n",
        "print(\"\\nBottom 10 Least Important (Most Regularized) Features:\")\n",
        "print(bottom_features)\n",
        "\n",
        "# 8. Plot learning curve (use same model settings)\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(penalty='l1', solver='liblinear', C=0.5, max_iter=1000),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plotting\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression with Rolling Averages and L1 Regularization - Pre 2020)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ESGNCaMXbY3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# post 2020\n",
        "# 1. Define target variable\n",
        "df_post2020['Win'] = (df_post2020['Winner'] == df_post2020['Team 1']).astype(int)\n",
        "\n",
        "# 2. Select only differential features THAT ALSO are rolling averages\n",
        "all_diff_features = [col for col in df_post2020.columns if col.startswith(\"Diff \") and df_post2020[col].notna().all()]\n",
        "diff_features = [col for col in all_diff_features if 'Games Played' not in col]\n",
        "\n",
        "# 3. Create X and y\n",
        "X = df_post2020[diff_features].copy()\n",
        "y = df_post2020['Win']\n",
        "\n",
        "# 4. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Train logistic regression\n",
        "model_post2020 = LogisticRegression(penalty='l1', solver='liblinear', C=0.05)\n",
        "model_post2020.fit(X_train, y_train)\n",
        "\n",
        "# 6. Evaluate model\n",
        "y_pred = model_post2020.predict(X_test)\n",
        "accuracy_post2020 = accuracy_score(y_test, y_pred)\n",
        "f1_post2020 = f1_score(y_test, y_pred)\n",
        "report_post2020 = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_post2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred):.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_post2020)\n",
        "\n",
        "# 7. Feature importance\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_post2020.coef_[0]\n",
        "})\n",
        "\n",
        "# Top 10 most important\n",
        "top_features = coef_df.reindex(coef_df['Coefficient'].abs().sort_values(ascending=False).index).head(10)\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(top_features)\n",
        "\n",
        "# Bottom 10 least important (including zeros)\n",
        "bottom_features = coef_df.reindex(coef_df['Coefficient'].abs().sort_values(ascending=True).index).head(10)\n",
        "print(\"\\nBottom 10 Least Important (Most Regularized) Features:\")\n",
        "print(bottom_features)\n",
        "\n",
        "# 8. Plot learning curve\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(penalty='l1', solver='liblinear', C=0.05),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plotting\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression with Rolling Averages and L1 Regularization - Post 2020)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sYririPPdSu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Running Logistic Regression with L2 Regularization"
      ],
      "metadata": {
        "id": "Zb6jJbBMUJuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, learning_curve\n",
        "from sklearn.metrics import classification_report, accuracy_score, make_scorer, f1_score"
      ],
      "metadata": {
        "id": "aGeN7vSYUJu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre 2020\n",
        "\n",
        "# 1. Define target variable\n",
        "df_pre2020['Win'] = (df_pre2020['Winner'] == df_pre2020['Team 1']).astype(int)\n",
        "\n",
        "# 2. Select only differential features (rolling averages only)\n",
        "all_diff_features = [col for col in df_pre2020.columns if col.startswith(\"Diff \") and df_pre2020[col].notna().all()]\n",
        "diff_features = [col for col in all_diff_features if 'Games Played' not in col]\n",
        "\n",
        "# 3. Create X and y\n",
        "X = df_pre2020[diff_features].copy()\n",
        "y = df_pre2020['Win']\n",
        "\n",
        "# 4. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Train logistic regression with L1 regularization\n",
        "model_pre2020 = LogisticRegression(penalty='l2', solver='liblinear', C=0.01, max_iter=1000)\n",
        "model_pre2020.fit(X_train, y_train)\n",
        "\n",
        "# 6. Evaluate model\n",
        "y_pred = model_pre2020.predict(X_test)\n",
        "accuracy_pre2020 = accuracy_score(y_test, y_pred)\n",
        "f1_pre2020 = f1_score(y_test, y_pred)\n",
        "report_pre2020 = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_pre2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred):.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_pre2020)\n",
        "\n",
        "# 7. Feature importance\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_pre2020.coef_[0]\n",
        "})\n",
        "\n",
        "# Top 10 most important\n",
        "top_features = coef_df.reindex(coef_df['Coefficient'].abs().sort_values(ascending=False).index).head(10)\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(top_features)\n",
        "\n",
        "# Bottom 10 least important (including zeros)\n",
        "bottom_features = coef_df.reindex(coef_df['Coefficient'].abs().sort_values(ascending=True).index).head(10)\n",
        "print(\"\\nBottom 10 Least Important (Most Regularized) Features:\")\n",
        "print(bottom_features)\n",
        "\n",
        "# 8. Plot learning curve (use same model settings)\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(penalty='l1', solver='liblinear', C=0.01, max_iter=1000),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plotting\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression with Rolling Averages and L2 Regularization - Pre 2020)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "b44XURSgUJu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# post 2020\n",
        "# 1. Define target variable\n",
        "df_post2020['Win'] = (df_post2020['Winner'] == df_post2020['Team 1']).astype(int)\n",
        "\n",
        "# 2. Select only differential features THAT ALSO are rolling averages\n",
        "all_diff_features = [col for col in df_post2020.columns if col.startswith(\"Diff \") and df_post2020[col].notna().all()]\n",
        "diff_features = [col for col in all_diff_features if 'Games Played' not in col]\n",
        "\n",
        "# 3. Create X and y\n",
        "X = df_post2020[diff_features].copy()\n",
        "y = df_post2020['Win']\n",
        "\n",
        "# 4. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Train logistic regression\n",
        "model_post2020 = LogisticRegression(penalty='l2', solver='liblinear', C=0.01)\n",
        "model_post2020.fit(X_train, y_train)\n",
        "\n",
        "# 6. Evaluate model\n",
        "y_pred = model_post2020.predict(X_test)\n",
        "accuracy_post2020 = accuracy_score(y_test, y_pred)\n",
        "f1_post2020 = f1_score(y_test, y_pred)\n",
        "report_post2020 = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_post2020:.3f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred):.3f}\")\n",
        "print(\"\\nClassification Report:\\n\", report_post2020)\n",
        "\n",
        "# 7. Feature importance\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': diff_features,\n",
        "    'Coefficient': model_post2020.coef_[0]\n",
        "})\n",
        "\n",
        "# Top 10 most important\n",
        "top_features = coef_df.reindex(coef_df['Coefficient'].abs().sort_values(ascending=False).index).head(10)\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(top_features)\n",
        "\n",
        "# Bottom 10 least important (including zeros)\n",
        "bottom_features = coef_df.reindex(coef_df['Coefficient'].abs().sort_values(ascending=True).index).head(10)\n",
        "print(\"\\nBottom 10 Least Important (Most Regularized) Features:\")\n",
        "print(bottom_features)\n",
        "\n",
        "# 8. Plot learning curve\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=LogisticRegression(penalty='l1', solver='liblinear', C=0.01),\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 50),\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# 9. Plotting\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_sizes, train_mean, 'r-', label='training', marker='o')\n",
        "plt.plot(train_sizes, val_mean, 'b-', label='validation', marker='x')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='red', alpha=0.1)\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='blue', alpha=0.1)\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Learning Curve (Logistic Regression with Rolling Averages and L2 Regularization - Post 2020)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kxzqXlP8UJu0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}